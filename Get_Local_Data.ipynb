{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b><center>UNCLASSIFIED</center> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./GRAPHICS/Banner.png\" width=\"110%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5: Getting Local Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## Table of Contents\n",
    "\n",
    "* [5.1. Objectives](#Objectives)<br>\n",
    "* [5.2. Overview](#Overview)<br>\n",
    "* [5.3. Review](#review)<br>\n",
    "    * [5.3.1. Data Types and Structures](#DataTypes)<br>\n",
    "    * [5.3.2. Operators, If Statements, and For Loops](#Flow)<br>\n",
    "    * [5.3.3. Functions](#Functions)<br>\n",
    "* [5.4. Lesson: Getting Data](#Lesson)<br>\n",
    "    * [5.4.1. Entering Data from the Prompt](#EnteringData)<br>\n",
    "    * [5.4.2. Loading a Local Data File](#LoadingData)<br>\n",
    "* [5.5. Guided Exercise: Converting Latitude Geocoordinates from DMS to DD](#GuidedExercise)<br>\n",
    "* [5.6. Practical Exercises](#PracticalExercises)<br>\n",
    "    * [5.6.1. Practical Exercise 1: Converting a Longitude Geocoordinate from DMS to DD](#PE1)<br>\n",
    "    * [5.6.2. Practical Exercise 2: Searching for Key Words](#PE2)<br>\n",
    "* [5.7. Administrative Notes](#Administrative)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Objectives\"></a>\n",
    "## 5.1. Objectives\n",
    "Using conditionals, loops, Python dictionaries, local data, the CSV Library, and the Glob Library, students will be able to:\n",
    "- Examine the implications of using computation to solve a problem\n",
    "  - Discuss best practices for using computation to solve a problem\n",
    "  - Suggest types of problems that can be solved through computation\n",
    "  - Show how computation can solve a problem\n",
    "     <br><br>\n",
    "- Recognize key computer science concepts\n",
    "  - Recognize how queries operate\n",
    "  <br><br>\n",
    "- Demonstrate the ability to build basic scripts using Python scripting language\n",
    "  - Collect data using Python scripting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a id=\"Overview\"></a>\n",
    "## 5.2. Overview\n",
    "The following lesson in broken up into three main parts:\n",
    "\n",
    "* Lesson: Getting Data\n",
    "* Guided Exercise: Converting Latitude Geocoordinates\n",
    "* Practical Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"brick\">Instructor Guidance</font>: Refer back to Lesson 1 and relate the four steps of problem-solving using Computational Thinking (Decomposition, Pattern Recognition, Abstraction, & Algorithm Design) to lessons, exercises, examples, student questions/comments, etc., as appropriate throughout this lesson.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> <a id='review'></a>\n",
    "## 5.3. Review \n",
    "\n",
    "The review below will cover data types, data structures, operators, <font color=\"green\">**if**</font> statements, <font color=\"green\">**for**</font> loops, and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"firebrick\">Instructor Guidance: </font>Pick a student to answer each question.  If a student does not have the answer, try to work through the problem with the student.  If the student is still unable to give a correct answer, move to the next student.  <b>DO NOT</b> give the answers to the class unless you see a general lack of comprehension.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><a id='DataTypes'></a>\n",
    "### 5.3.1. Data Types and Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1. How would you use casting to fix the code cell below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are sick.\n"
     ]
    }
   ],
   "source": [
    "body_temp = '98.6' \n",
    "my_temp = 98.6\n",
    "\n",
    "if my_temp != body_temp:   \n",
    "    print('You are sick.')\n",
    "else:\n",
    "    print('No Fever')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Fever\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "body_temp = '98.6' \n",
    "my_temp = 98.6\n",
    "\n",
    "if my_temp != float(body_temp):\n",
    "    print('You are sick.')\n",
    "else:\n",
    "    print('No Fever')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2. Describe how to take the string below and create two new strings, one in all lower case and the other in all upper case. Print those strings out. \n",
    "\n",
    "HINT: This will use two different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_string = 'HOw aRe We liKIng ClAsS so fAR?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how are we liking class so far?\n",
      "HOW ARE WE LIKING CLASS SO FAR?\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "new_string = 'HOw aRe We liKIng ClAsS so fAR?'\n",
    "\n",
    "lower_string = new_string.lower()\n",
    "upper_string = new_string.upper()\n",
    "print(lower_string)\n",
    "print(upper_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3. Name the types of these four data structures and state which are mutable:\n",
    "\n",
    "| Data Structure       | \n",
    "| :--------------:|\n",
    "| `['a', 'b', 'c']`   |     \n",
    "| `(1, 2, 4, 2, 7)`      | \n",
    "| `{'a': 1, 'b': 2, 'c': 3}` | \n",
    "|` {1, 3, 5, 8}`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "\n",
    "## ['a','b','c']          List (mutable) ## \n",
    "## (1,2,4,2,7)            Tuple (immutable) ## \n",
    "## {'a':1,'b':2,'c':3}    Dictionary (mutable) ##   \n",
    "## {1,3,5,8}              Set (mutable) ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"brick\">Instructor Guidance: </font>Ask a student to name the keys in the dictionary, then name the values. Ask another student what is unique about a set (it only holds unique values).</b>\n",
    "\n",
    "<b><font color=\"brick\">Instructor Guidance: </font>Questions 2.1.4. and 2.1.5. should be asked to the whole class.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4. Use the index number of `'Bert'` to print `'Bert'` from the list below, use a negative index number to print `'Tina'`, and use index numbers with a colon to create a slice and print the list `['Tom', 'Joe']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_x = ['Bert', 'Tom', 'Joe', 'Tina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert\n",
      "Tina\n",
      "['Tom', 'Joe']\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "list_x = ['Bert', 'Tom', 'Joe', 'Tina']\n",
    "\n",
    "print(list_x[0])\n",
    "print(list_x[-1])\n",
    "print(list_x[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 5. Use casting and the `len()` function to identify the number of unique integers in the list below. \n",
    "\n",
    "HINT: The answer is 45."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_list = [9, 36, 5, 8, 38, 93, 90, 32, 7, 436, 10, 981, 23, 983, 1, 10, 436, 22, 5, 80, 36, 5, 1, 1234, 34, 40, 719, 707, 4, 238, 5, 6, 1, 90, 52, 19, 71, 71, 36, 5, 1000, 67, 23, 7, 3, 8, 3, 0, 85, 6, 1, 5, 1, 56, 7129, 8, 5, 7, 60, 92, 51, 2, 44, 256, 82, 1, 90, 983, 1, 55, 53, 12835]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "len(set(my_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 6. Use `.extend()`, `.append()`, and `.insert()` to combine the partial lists of digits below, then add the digits `3` and `9` to create a single complete list of digits (`0` through `9` inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "part_list_a = [0, 1, 2, 4, 5]\n",
    "part_list_b = [6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "part_list_a = [0, 1, 2, 4, 5]\n",
    "part_list_b = [6, 7, 8] \n",
    "\n",
    "part_list_a.extend(part_list_b)\n",
    "\n",
    "part_list_a.append(9)  \n",
    "\n",
    "part_list_a.insert(3, 3)\n",
    "\n",
    "part_list_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 7. Using the dictionary defined below, reassign the value of `'Pam'` to a real clearance level. Also, add `'Stan'`, give him the status `'Uncleared'`, and print Stan's status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_a = {'Dan': 'Top Secret', 'Beth': 'Secret', 'Keith': 'Top Secret', 'Pam': 'SuperDuper Secret'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret\n",
      "Uncleared\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "dict_a = {'Dan': 'Top Secret', 'Beth': 'Secret', 'Keith': 'Top Secret', 'Pam': 'SuperDuper Secret'}\n",
    "\n",
    "dict_a['Pam'] = 'Secret'\n",
    "print(dict_a['Pam'])\n",
    "\n",
    "dict_a['Stan'] = 'Uncleared'\n",
    "print(dict_a['Stan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> <a id='Flow'></a>\n",
    "### 5.3.2. Operators, If Statements, and For Loops\n",
    "<img src=\"./GRAPHICS/IfElse.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1. Explain the difference between these operators: `=`, `!=`, and `==`. Then, use these operators to write two expressions below, one that evaluates to <font color=\"green\"><b>True</b></font> and one that evaluates to <font color=\"green\"><b>False</b></font>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "x = 5           ## \"=\" is for assigning values to variables ##\n",
    "\n",
    "print(4 != x)   ## \"!=\" is for assessing if two values are not equal ##\n",
    "\n",
    "print(4 == x)   ## \"==\" is for assessing if two values are equal ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2. Read the <font color=\"green\">**if**</font> statement below and talk through how the <font color=\"green\">**if**</font>, <font color=\"green\">**elif**</font>, and <font color=\"green\">**else**</font> work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eating breakfast\n"
     ]
    }
   ],
   "source": [
    "food = 'Bagel'\n",
    "\n",
    "if food == 'Burger':             \n",
    "    print('Eating lunch')        \n",
    "\n",
    "elif 'Bagel' in food:            \n",
    "    print('Eating breakfast')    \n",
    "    \n",
    "else:\n",
    "    print(\"I'm hungry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3. Describe three ways to change the code below so that `'Eating lunch'` is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eating breakfast\n"
     ]
    }
   ],
   "source": [
    "food = 'Bagel'                  \n",
    "                               \n",
    "if food == 'Burger':            \n",
    "    print('Eating lunch')\n",
    "    \n",
    "elif 'Bagel' in food:           \n",
    "    print('Eating breakfast')  \n",
    "    \n",
    "else:\n",
    "    print(\"I'm hungry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"brick\">Instructor Guidance: </font>Ask the class what other changes could get `'Eating lunch'` to print out. Give hints about using different operators: <font color=green>!=</font>, <font color=green>not</font>, etc.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4 Write a <font color=green>**for**</font> loop with a nested <font color=green>**if**</font> statement(s) that will print the numbers from `number_list` that are _greater_ than `4` and _less than_ `8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_list = [1, 7, 5, 0, 8, 15, 3, 6, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "number_list = [1, 7, 5, 0, 8, 15, 3, 6, 10]\n",
    "\n",
    "for item in number_list:\n",
    "    \n",
    "    if 4 < item < 8:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 5. Write a <font color=green>**for**</font> loop with a nested <font color=green>**if**</font> statement that will add the numbers from `number_list` that are _greater than_ 4 and _less than_ 8 to a new list, then print that list. \n",
    "\n",
    "HINT: You can steal from the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"brick\">Instructor Guidance: </font>Talk about the importance of changing variables when you \"borrow\" code.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 5, 6]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "number_list = [1, 7, 5, 0, 8, 15, 3, 6, 10]\n",
    "\n",
    "new_list = []\n",
    "\n",
    "for item in number_list:\n",
    "    \n",
    "    if 4 < item < 8:\n",
    "        new_list.append(item)\n",
    "        \n",
    "new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 6. Write some code that will take the strings from `jumbled_list` below and add them to a new list, then print that list. \n",
    "\n",
    "HINT: You can steal from the code above and make just a couple changes.\n",
    "\n",
    "BONUS: Join the list into a single string before you print it out using the `.join()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jumbled_list = ['2', 3, 5, 10, '8', 7, '0', 9, 13, '18', 99, 34, '72', 53, '28', 8, 14, '46', 99, '81', 32, 30, 1, '64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '8', '0', '18', '72', '28', '46', '81', '64']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'280187228468164'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "jumbled_list = ['2', 3, 5, 10, '8', 7, '0', 9, 13, '18', 99, 34, '72', 53, '28', 8, 14, '46', 99, '81', 32, 30, 1, '64']\n",
    "\n",
    "string_list = []\n",
    "\n",
    "for item in jumbled_list:\n",
    "    \n",
    "    if type(item) == str:\n",
    "        string_list.append(item)\n",
    "        \n",
    "print(string_list)\n",
    "''.join(string_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 7. Change the logic operators (<font color=\"green\"><b>and</b></font> and <font color=\"green\"><b>or</b></font>) or the membership operators (<font color=\"green\"><b>in</b></font> and <font color=\"green\"><b>not in</b></font>) so the statements below evaluate to <font color=\"green\"><b>True</b></font>. After fixing each statement, explain how Python evaluates the statement to <font color=green>**True**</font>. The first `print()` statement is done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NATO = ['Belgium', 'Canada', 'Denmark', 'France', 'Iceland', 'Italy', 'Luxembourg', 'Netherlands',\n",
    "        'Norway', 'Portugal', 'United Kingdom', 'United States', 'Greece', 'Turkey', 'Germany',\n",
    "        'Spain', 'Czech Republic', 'Hungary', 'Poland', 'Bulgaria', 'Estonia', 'Latvia',\n",
    "        'Lithuania', 'Romania', 'Slovakia', 'Slovenia', 'Albania', 'Croatia', 'Montenegro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('Russia' in NATO) or ('Sweden' not in NATO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'United Kingdom' not in NATO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('United Kingdom' in NATO) and ('Sweden' in NATO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('China' not in NATO) and ('Sweden' not in NATO) and ('United States' not in NATO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 8. Explain how the assignment operator `+=` works. What does `x` evaluate to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 10\n",
    "x += 5\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> <a id='Functions'></a>\n",
    "### 5.3.3. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1. Define a function that takes as inputs, 1) a dictionary of names and clearance levels, and 2) a given clearance level, and then returns a list of names that have the given clearance in the dictionary. If no one has the given clearance, make the function return <font color=green>**None**</font>. \n",
    "\n",
    "Name your function `clearance_checker()`, and make the inputs match the sample cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"brick\">Instructor Guidance: </font>Type out the student's code as it is described.  If the student needs help, encourage other students to help.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "team_bravo_clearances = {'Abe': 'Double Top Secret',\n",
    "                         'Barry': 'Top Secret',\n",
    "                         'Beth': 'Secret',\n",
    "                         'Carla': 'Uncleared',\n",
    "                         'Carlos': 'Top Secret',\n",
    "                         'Dan': 'Top Secret',\n",
    "                         'Darlene': 'Top Secret',\n",
    "                         'Darryl': 'Double Top Secret',\n",
    "                         'Deb': 'Secret',\n",
    "                         'George': 'Secret',\n",
    "                         'Jackie': 'Secret',\n",
    "                         'Jen': 'Uncleared',\n",
    "                         'Keith': 'Top Secret',\n",
    "                         'Pam': 'SuperDuper Secret',\n",
    "                         'Stan': 'Uncleared'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jackie', 'Beth', 'George', 'Deb']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "def clearance_checker(agent_dict, clearance_level):\n",
    "    \n",
    "    output_list = []\n",
    "    \n",
    "    for name, clearance in agent_dict.items():\n",
    "        \n",
    "        if clearance == clearance_level:\n",
    "            output_list.append(name)\n",
    "\n",
    "    if output_list == []:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        return output_list\n",
    "\n",
    "clearance_checker(team_bravo_clearances, 'Secret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2. Describe what happens when you try to print a function that returns no output. Try running the code cell below. Can you point out the line of code that produces each printed line of output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def bad_function(int_a, int_b):\n",
    "    int_c = int_a + int_b\n",
    "    print(int_c)\n",
    "    \n",
    "print(bad_function(5, 4))\n",
    "\n",
    "list_a = [2, 4, 6, 8]\n",
    "print(list_a.append(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a id='Lesson'></a>\n",
    "## 5.4. Lesson: Getting Local Data\n",
    "\n",
    "Getting data to load into Python is a practical skill to have and practice.  Throughout this course, we'll cover a number of methods for reading and writing structured and unstructured data using Python. One of the great things about Python is that there are many ways to accomplish the same task.  This is true with getting data. In this lesson we will cover two ways of getting data.\n",
    "\n",
    "<hr>\n",
    "<a id='EnteringData'></a>\n",
    "### 5.4.1. Entering Data From the Prompt\n",
    "<hr>\n",
    "#### References:\n",
    "* [Python 3.5 input()](https://docs.python.org/3/library/functions.html#input)\n",
    "\n",
    "<hr>\n",
    "\n",
    "The easiest way to get data into a Python program is to use the `input()` function. This function asks the user to type data into a dialog box. This is sometimes called _prompting_ the user. To implement `input()` in your Python program, use the following syntax:\n",
    "\n",
    "```python\n",
    "variable_name = input(optional_prompt_string)\n",
    "```\n",
    "\n",
    "Below is a simple working example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your name: bob\n",
      "Hello bob! Your name spelled backwards is Bob\n"
     ]
    }
   ],
   "source": [
    "name = input('Please enter your name: ')\n",
    "\n",
    "print('Hello ' + name + '! Your name spelled backwards is ' + name[::-1].title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we ask the user for keyboard input and save it to a variable. What is happening in the second line of the code? We haven't seen this notation before:\n",
    "\n",
    "```python\n",
    "name[::-1]\n",
    "```\n",
    "\n",
    "This is actually a slice, but insted of passing just a start and stop parameter, we also pass a third parameter called a _step_. This tells our code how to move through the sequence. In this case a step of `-1` moves backwards through the `name` string. Take the code from above and modify it for a new use. Using the mostly filled out skeleton code below as a template, fill in a conditional that will check to see if the input string is a [palindrome](https://en.wikipedia.org/wiki/Palindrome)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# name = input('Is your name a palindrome? Please enter your name: ')\n",
    "\n",
    "if ## << Enter your conditional here >> ##\n",
    "    print(name + ', your name is a palindrome.')\n",
    "else:\n",
    "    print(name + ', your name is not a palindrome.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is your name a palindrome? Please enter your name: b\n",
      "b, your name is a palindrome.\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "name = input('Is your name a palindrome? Please enter your name: ')\n",
    "\n",
    "if name[::-1].lower() == name.lower():\n",
    "    print(name + ', your name is a palindrome.')\n",
    "else:\n",
    "    print(name + ', your name is not a palindrome.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Follow-Up Question:\n",
    "1. Would this solution work for palindromic numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> <a id='LoadingData'></a>\n",
    "### 5.4.2. Loading a Local Data File\n",
    "<hr>\n",
    "#### References:\n",
    "* [Python 3.5 open()](https://docs.python.org/3.5/library/functions.html#open)\n",
    "* [Python Tutorial - Reading and Writing Files](https://docs.python.org/2/tutorial/inputoutput.html#reading-and-writing-files)\n",
    "<hr>\n",
    "\n",
    "#### 5.4.2.1. Built-in `open()` Function\n",
    "A second method for getting data into a Python program involves reading a local file using the built-in `open()` function.\n",
    "\n",
    "The `open()` function looks like this:\n",
    "```python\n",
    "open(filename)\n",
    "```\n",
    "\n",
    "The `open()` function creates a connection between your Python script and a file on your computer. This connection is sometimes called a _file stream_. The argument it takes is a string pointing to a file on your computer. Once a file stream is opened, it must be closed for the file to be saved for access at a later time. Python can connect to a file in various modes, the most basic of which are `'r'` (read mode) and `'w'` (write mode).\n",
    "\n",
    "The methodology for reading from (or writing to) a local file consists of three basic steps:\n",
    "\n",
    ">Step 1. Open the file. <br>\n",
    ">Step 2. Read or write the contents of the file.<br>\n",
    ">Step 3. Close the file.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remembering to close the file is an easy step to skip. Luckily, we don't have to remember to close the file if we use the <b><font color=\"green\">with</font></b> keyword to store the file stream in a temporary variable. We can write our code to read or write indented under the <b><font color=\"green\">with</font></b> statement, and the file will close automatically when the indentation ends. \n",
    "\n",
    "* To read a file, mode is `'r'`. (This is the default mode, so if you don't pass a `mode` argument the mode is `'r'`.)\n",
    "* To write a file, mode is `'w'`.\n",
    "\n",
    "Below is an example of what a <b><font color=\"green\">with</font></b> block looks like. In this example, `my_file` is the temporary variable created by the <b><font color=\"green\">with</font></b> statement. It holds the file stream. We then call `.write()` on the file to write data to the file. `.write()` always writes your data out as a string.\n",
    "\n",
    "```python\n",
    "with open(filename, mode='w') as my_file:\n",
    "    my_file.write(data)\n",
    "```\n",
    "\n",
    "The code to read in data from a file looks very similar. Can you spot all the differences?\n",
    "\n",
    "```python\n",
    "with open(filename, mode='r') as my_file:\n",
    "    data = my_file.read()\n",
    "```\n",
    "\n",
    "The variable `filename` above points your script to the file you want to read or write to. By default, Python will look for files in your current folder, that is, the folder where your script or notebook is stored. If you want to read or write to a file in a different folder, `filename` must include the _path_ to that folder. Most of the time, you'll use what's called the _relative path_. The relative path tells Python all the steps to take to get from the current folder to the destination folder. The path is a string in which we put a slash (`/`) after each folder name. A path to a file called `my_data.csv` could look something like this:\n",
    "\n",
    "```python\n",
    "'folder_1/folder_2/folder_2/my_data.csv'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2.2. Read in a Resume\n",
    "Let's read in Kermit the Frog's Resume from the file `guided_exercise_01.txt` and print it to the screen. This file is stored in the folder called `data/` in your current folder, so we need to specify that in addition to the file name. Since we want to open the file in read mode, we don't need to pass a `mode` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kermit T. Frog\n",
      "123 Sesame Street, New York, NY 10010-0101\n",
      "\n",
      "800-867-5309 | kermie_baby@gmail.com | http://www.imdb.com/name/nm1463454/ | https://en.wikipedia.org/wiki/Kermit_the_Frog\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PROFILE\n",
      "Actor with a strong math background and experience in counting numbers, learning, and managing a bunch of Muppets.  Passionate about the performing arts, Children's education, and explaining data science to non-technical business audiences under the age of 10.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "RECENT WORK EXPERIENCE\n",
      "\n",
      "The Muppets Studio, LLC (2004 - present)\n",
      "The Muppets Studio, LLC, formerly The Muppets Holding Company, LLC, is a wholly owned entertainment subsidiary of Disney Consumer Products and Interactive Media Labs, formed in 2004 through The Walt Disney Company's acquisition of The Muppets, Fraggle Rock and Bear in the Big Blue House intellectual properties from The Jim Henson Company.\n",
      "\n",
      "The Muppet Show (1976 - 1981)\n",
      "The Muppet Show is a family-oriented comedy-variety television series that was produced by puppeteer Jim Henson and features The Muppets. After two pilot episodes produced in 1974 and 1975 failed to get the attention of network executives in the United States, Lew Grade approached Henson to produce the programme in the United Kingdom for ATV. The show lasted for five series consisting of 120 episodes which were first broadcast in Britain between 5 September 1976 and 15 March 1981 on ATV and was shown by the other ITV franchises in the United Kingdom. The programs were recorded at Elstree Studios, England.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "TECHNICAL SKILLS\n",
      "Talent and Production Management\n",
      "Public Relations\n",
      "Performing Arts\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "EDUCATION\n",
      "The Children's Workshop - 1971\n",
      "Julliard School of Performing Arts - 1974\n",
      "Master of Arts in Mathematics, PhD Candidate (left program ABD)\n",
      "Honorary Doctorate of Amphibious Letters, Southampton College - May 1996\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "HONORS AND AWARDS\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "SELECTED FILMOGRAPHY\n",
      "Sam and Friends (1955â€“1961) (TV)\n",
      "Sesame Street (1969â€“1990, 1996â€“2001, and 2009) (TV)\n",
      "Hey, Cinderella! (1969) (TV)\n",
      "The Muppets on Puppets (1970) (TV)\n",
      "The Frog Prince (1971) (TV)\n",
      "The Muppets Valentine Show (1974) (TV)\n",
      "The Muppet Show: Sex and Violence (1975) (TV)\n",
      "The Muppet Show (1976â€“1981) (TV)\n",
      "Emmet Otter's Jug-Band Christmas (1977) (TV)\n",
      "The Muppet Movie (1979)\n",
      "The Great Muppet Caper (1981)\n",
      "The Muppets Take Manhattan (1984)\n",
      "Muppet Babies (1984â€“1991) (TV)\n",
      "Sesame Street Presents Follow That Bird (1985)\n",
      "The Muppets: A Celebration of 30 Years (1986) (TV)\n",
      "The Christmas Toy (1986) (TV)\n",
      "A Muppet Family Christmas (1987) (TV)\n",
      "The Jim Henson Hour (1989) (TV)\n",
      "Cartoon All-Stars to the Rescue (1990) (TV)\n",
      "The Muppets at Walt Disney World (1990) (TV)\n",
      "The Muppets Celebrate Jim Henson (1990) (TV)\n",
      "The Muppet Christmas Carol (1992) â€“ Appearance as Bob Cratchit\n",
      "Muppet Classic Theater (1994) (Direct-to-Video) - Appearance as King Midas and the King in Rumpelstiltskin.\n",
      "Muppet Treasure Island (1996) â€“ Appearance as Captain Abraham Smollett\n",
      "Muppets Tonight (1996â€“1998) (TV)\n",
      "Muppets from Space (1999)\n",
      "Kermit's Swamp Years (2002) (Direct-to-Video)\n",
      "It's a Very Merry Muppet Christmas Movie (2002) (TV)\n",
      "Saturday Night Live (2004, 2011) (TV)\n",
      "The Muppets' Wizard of Oz (2005) (TV) â€“ Appearance as Himself and The Scarecrow\n",
      "Mr. Magorium's Wonder Emporium (2007) (cameo)\n",
      "Studio DC: Almost Live (2008) (TV)\n",
      "A Muppets Christmas: Letters to Santa (2008) (TV)\n",
      "The Muppets (2011)\n",
      "Lady Gaga and the Muppets Holiday Spectacular (2013) (TV)\n",
      "Muppets Most Wanted (2014)\n",
      "The Muppets (2015-2016) (TV)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/guided_exercise_01.txt') as my_file: \n",
    "    kermit_resume = my_file.read()\n",
    "\n",
    "print(kermit_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the code under <font color=green>**with**</font> is executed, the `my_file` variable is closed, so we can't read from it anymore.  What happens if we try?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-62aed17d4539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "my_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, error messages are helpful, not harmful. This one says `ValueError: I/O operation on closed file.` `I/O` stands for Input/Output. This error is saying that we cannot call `.read()` on a closed file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2.3. Read in a More Complicated File\n",
    "Read in the file `USGS_earthquake_data.xml` from your `data/` folder. This data was pulled from the [USGS Earthquake Hazards Program](https://earthquake.usgs.gov/) website on 17 August 2017. You can view the [USGS All Earthquakes, Past Hour](https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_hour.atom) on the USGS Earthquake Hazards Program website. As the file extension indicates, this is an XML file. Let's see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\" xmlns:georss=\"http://www.georss.org/georss\"><title>USGS All Earthquakes, Past Hour</title><updated>2017-08-18T02:10:18Z</updated><author><name>U.S. Geological Survey</name><uri>https://earthquake.usgs.gov/</uri></author><id>https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_hour.atom</id><link rel=\"self\" href=\"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_hour.atom\"/><icon>https://earthquake.usgs.gov/favicon.ico</icon>\\n<entry><id>urn:earthquake-usgs-gov:us:2000a98e</id><title>M 2.5 - 81km W of Miramichi, Canada</title><updated>2017-08-18T01:47:05.040Z</updated><link rel=\"alternate\" type=\"text/html\" href=\"https://earthquake.usgs.gov/earthquakes/eventpage/us2000a98e\"/><summary type=\"html\"><![CDATA[<dl><dt>Time</dt><dd>2017-08-18 01:26:42 UTC</dd><dd>2017-08-17 21:26:42 -04:00 at epicenter</dd><dt>Location</dt><dd>46.980&deg;N 66.536&deg;W</dd><dt>Depth</dt><dd>9.00 km (5.59 mi)</dd></dl>]]></summary><georss:point>465847.64N 0663209.60W</georss:point><georss:elev>-9000</georss:elev><category label=\"Age\" term=\"Past Hour\"/><category label=\"Magnitude\" term=\"Magnitude 2\"/><category label=\"Contributor\" term=\"us\"/><category label=\"Author\" term=\"us\"/></entry>\\n</feed>'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/USGS_earthquake_data.xml') as my_file:\n",
    "    USGS_xml_data = my_file.read()\n",
    "\n",
    "USGS_xml_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Extensible Mark-up Language ([XML](https://en.wikipedia.org/wiki/XML)) format is human-readable and machine-readable. It may look familiar as it is similar to the structure of HTML, which is used to build web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2.4. Use `.find()` to Extract Information \n",
    "Now that we have some structured data, lets practice using the `.find()` method to extract some information. Take a few minutes and work through the questions below:\n",
    "\n",
    ">1. What sub-strings (tags) would allow us to extract the date/time and location of the earthquake?\n",
    ">2. Where did the earthquake occur? How could we extract this information?\n",
    ">3. There is some unhelpful text in the data extracted. What are some ways to get rid of this data?\n",
    ">4. What other information could be extracted from the USGS data?\n",
    "\n",
    "Exercise: Extract the time and location information from the XML data stored in `USGS_xml_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-18 01:26:42 UTC\n",
      "M 2.5 - 81km W of Miramichi, Canada\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "time_start = USGS_xml_data.find('<dt>Time</dt>')\n",
    "time_stop = USGS_xml_data.find('</dd>')\n",
    "\n",
    "time = USGS_xml_data[time_start:time_stop]\n",
    "\n",
    "start = USGS_xml_data.find('<entry>')\n",
    "loc_start = USGS_xml_data.find('</id><title>', start)\n",
    "loc_stop = USGS_xml_data.find('</title><updated>', start)\n",
    "\n",
    "loc = USGS_xml_data[loc_start:loc_stop]\n",
    "\n",
    "print(time[17:])\n",
    "print(loc[12:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "#### 5.4.2.5. Write a File\n",
    "\n",
    "The code below will write out the  location and time data we just found to a file called `USGS_Cleaned.txt`. By default, the new file will be created in your current working folder, the same folder that holds this Jupyter Notebook. We could change that by adding a path with folder names and slashes (`/`) to the beginning of the file name. Note that when we open a file for the purpose of writing to it, we need to pass the `'w'` mode argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('USGS_Cleaned.txt', 'w') as f:\n",
    "    f.write(loc[12:])\n",
    "    \n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write(time[17:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: If the file already exists, opening the file in `'w'` mode will clear its current contents. \n",
    "\n",
    "Exercise: Load the file we just wrote, `USGS_Cleaned.txt`, into a variable named `usgs_reread` and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try some code ideas here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M 2.5 - 81km W of Miramichi, Canada\\n2017-08-18 01:26:42 UTC'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "with open('USGS_Cleaned.txt') as f:\n",
    "    usgs_reread = f.read()\n",
    "\n",
    "usgs_reread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a id='GuidedExercise'></a>\n",
    "## 5.5. Guided Exercise: Converting Latitude Geocoordinates from Degrees-Minutes-Seconds (DMS) to Decimal Degrees (DD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color = \"brick\">Instructor Guidance</font>: Refer back to Lesson 1 and relate the four steps of problem-solving using Computational Thinking (Decomposition, Pattern Recognition, Abstraction, & Algorithm Design) as appropriate throughout these exercises.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "#### References:\n",
    "* [Wikipedia: Geographic Coordinate Conversion](https://en.wikipedia.org/wiki/Geographic_coordinate_conversion#Coordinate_format_conversion)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./GRAPHICS/LatLong.png\" width=\"45%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"brick\">Instructor Guidance: </font>Talk about lat/lon in the context of this picture so everyone is on the same page. </b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise involves nothing more than some string searches and some basic math.  Before we start to code, let's take a couple of minutes to think about the steps necessary to go from a DMS geocoordinate to its decimal equivalent. The DMS format is DDMMSSN/S or DDDMMSSE/W. Decimal degrees are a single number captures minutes and sections as fractions of a degree.\n",
    "\n",
    "NOTE: If the latitude is south, or the longitude is west, the decimal degrees value will be negative.\n",
    "\n",
    "Example: If we input the latitude `'853205S'`, we expect to get back `-85.53472222222221`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DMS to DD Conversion Algorithm:\n",
    ">    Step 1. Get input in the acceptable DMS format of DDMMSSN/S or DDDMMSSE/W.<br>\n",
    ">    Step 2. Convert DMS degrees from a string to a float.<br>\n",
    ">    Step 3. Convert DMS minutes from a string to a float, and divide by 60 to convert to a fraction.<br>\n",
    ">    Step 4. Convert DMS seconds from a string to a float, and divide by 3600 to convert to a fraction.<br>\n",
    ">    Step 5. Add up the converted values.<br>\n",
    ">    Step 6. If the latitude is south or longitude is west, multiply the equivalent decimal degrees by -1.<br>\n",
    ">    Step 7. Print the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Step 1. Get input in the acceptable DMS format of DDMMSSN/S or DDDMMSSE/W. We'll use a variable to store the DMS coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latitude_dms = '853205S'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Convert DMS degrees from a string to a float. First, we need to slice of the degree information from the larger DMS string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degrees = float(latitude_dms[:2])\n",
    "degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Convert DMS minutes from a string to a float. We slice off the minutes information, cast it to a float, and then divide by `60`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333333333333333"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minutes = float(latitude_dms[2:4]) / 60\n",
    "minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Convert DMS seconds from a string to a float. We slice off the seconds information, cast it to a float, and then divide by `3600`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001388888888888889"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seconds = float(latitude_dms[4:6]) / 3600\n",
    "seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. Add up the converted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.53472222222221"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = degrees + minutes + seconds\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6. If the latitude is south or longitude is west, multiply the equivalent decimal degrees by `-1`. We're just accounting for latitudes at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-85.53472222222221"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'S' in latitude_dms.upper():\n",
    "    dd *= -1\n",
    "    \n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7. Print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853205S ==> -85.53472222222221\n"
     ]
    }
   ],
   "source": [
    "print(latitude_dms, '==>', dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Let's put all of these steps in one code block. To make this script more user-friendly, we could call the `input()` function at the top to get the DMS coordinate rather than explicitly typing it into a variable. But for development purposes, using the explicitly initialized variable is easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853205S ==> -85.53472222222221\n"
     ]
    }
   ],
   "source": [
    "latitude_dms = '853205S'\n",
    "\n",
    "degrees = float(latitude_dms[:2])\n",
    "minutes = float(latitude_dms[2:4]) / 60\n",
    "seconds = float(latitude_dms[4:6]) / 3600\n",
    "\n",
    "dd = degrees + minutes + seconds\n",
    "\n",
    "if 'S' in latitude_dms.upper():\n",
    "    dd *= -1\n",
    "    \n",
    "print(latitude_dms, '==>', dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Follow-Up Questions:\n",
    "Question 1. How would your script have to change if the DMS format could be N/SDDMMSS as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latitude_dms = 'S853205'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slices we use to extract the data need to change, because the positions of each piece of information within the string change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S853205 ==> -85.53472222222221\n"
     ]
    }
   ],
   "source": [
    "if latitude_dms[-1] == 'N' or latitude_dms[-1] == 'S':  \n",
    "    dd = float(latitude_dms[:2])\n",
    "    dd += float(latitude_dms[2:4]) / 60\n",
    "    dd += float(latitude_dms[4:6]) / 3600\n",
    "    \n",
    "if latitude_dms[0] == 'N' or latitude_dms[0] == 'S':\n",
    "    dd = float(latitude_dms[1:3])\n",
    "    dd += float(latitude_dms[3:5]) / 60\n",
    "    dd += float(latitude_dms[5:]) / 3600\n",
    "\n",
    "if 'S' in latitude_dms:\n",
    "    dd = dd * -1\n",
    "\n",
    "print(latitude_dms, '==>', dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2. Does converting the string slices to integers rather than floats change the results? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S853205 ==> -85.53472222222221\n"
     ]
    }
   ],
   "source": [
    "if latitude_dms[-1] == 'N' or latitude_dms[-1] == 'S':  \n",
    "    dd = int(latitude_dms[:2])\n",
    "    dd += int(latitude_dms[2:4]) / 60\n",
    "    dd += int(latitude_dms[4:6]) / 3600\n",
    "    \n",
    "if latitude_dms[0] == 'N' or latitude_dms[0] == 'S':\n",
    "    dd = int(latitude_dms[1:3])\n",
    "    dd += int(latitude_dms[3:5]) / 60\n",
    "    dd += int(latitude_dms[5:]) / 3600\n",
    "\n",
    "if 'S' in latitude_dms:\n",
    "    dd = dd * -1\n",
    "\n",
    "print(latitude_dms, '==>', dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3. Data validation is a very important part of what data scientists do in the course of their work.  What things might you check in this example to ensure that valid geocoordinate data are being entered?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Possible Data Validation Steps: Data is invalid if...\n",
    "\n",
    ">1. Degrees latitude are greater than 90 or degrees longitude are greater than 180 <br>\n",
    ">2. Minutes or seconds are greater than 59 <br>\n",
    ">3. Letters or characters other than 'N','S','E', or 'W' in the input string <br>\n",
    ">4. Others? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a id='PracticalExercises'></a>\n",
    "## 5.6. Practical Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"brick\">Instructor Guidance</font>: Refer back to Lesson 1 and relate the four steps of problem-solving using Computational Thinking (Decomposition, Pattern Recognition, Abstraction, & Algorithm Design) as appropriate throughout these exercises.\n",
    "\n",
    "<font color=\"brick\">Instructor Guidance</font>: The practical exercises deemed most important due to content and/or a cumulative result, which should be completed first in the interest of maximum training value in relation to time are Practical Exercises 1.1, 1.2, and 2.1. Ensure you go over the exercise solutions and (as necessary) the processes to arrive at the solutions with the students.\n",
    "\n",
    "<font color=\"brick\">Instructor Guidance</font>: Follow-up questions are designed to be asked by the facilitators individually as each student completes the task and has it looked at by a facilitator.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='PE1'></a>\n",
    "### 5.6.1. Practical Exercise 1: Converting a Longitude Geocoordinate from DMS to DD\n",
    "<hr>\n",
    "#### References:\n",
    "* [Wikipedia: Geographic Coordinate Conversion](https://en.wikipedia.org/wiki/Geographic_coordinate_conversion#Coordinate_format_conversion)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.1.1. Practical Exercise 1.1\n",
    "\n",
    "Convert a longitude in DMS to DD. This is an extension from the Guided Exercise above.  Assume that the format is limited to DDDMMSSE/W.\n",
    "\n",
    "| Example Input | Expected Output |\n",
    "|:---:|:---:|\n",
    "|`1232334W`|`-123.39277777777778`|\n",
    "\n",
    "HINT: Recycle your code from the guided exercise but adjust your code as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232334W ==> -123.39277777777778\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "longitude_dms = '1232334W'\n",
    "\n",
    "degrees = int(longitude_dms[:3])\n",
    "minutes = int(longitude_dms[3:5]) / 60\n",
    "seconds = int(longitude_dms[5:-1]) / 3600\n",
    "\n",
    "dd = degrees + minutes + seconds\n",
    "\n",
    "if 'W' in longitude_dms.upper():\n",
    "    dd *= -1\n",
    "    \n",
    "print(longitude_dms, '==>', dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Follow-Up Questions:</b>\n",
    ">1. How is this algorithm different from the one in the Guided Exercise above?\n",
    ">2. How would your code need to change if the input could be either a latititude or a longitude?\n",
    ">3. What is the data type of the input? What is the data type of the output? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### 5.6.1.2. Practical Exercise 1.2\n",
    "\n",
    "Let's account for more valid formats. How would you convert the longitude to decimal degrees if the DMS format is DDD:MM:SS.ssssE/W?\n",
    "\n",
    "Example:\n",
    "    \n",
    "    123:23:34.5436W ==> -123.39292877777778\n",
    "    \n",
    "HINT: Recycle your code from the PE1 but account for the colons in the input string. You can change your slice indexes, or remove the colons from the string before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123:23:34.5436W ==> -123.39292877777778\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "longitude_dms_raw = '123:23:34.5436W'\n",
    "longitude_dms = longitude_dms_raw.replace(':', '')\n",
    "\n",
    "degrees = int(longitude_dms[:3])\n",
    "minutes = int(longitude_dms[3:5]) / 60\n",
    "seconds = float(longitude_dms[5:-1]) / 3600\n",
    "\n",
    "dd = degrees + minutes + seconds\n",
    "\n",
    "if 'W' in longitude_dms.upper():\n",
    "    dd *= -1\n",
    "    \n",
    "print(longitude_dms_raw, '==>', dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### 5.6.1.2. Practical Exercise 1.3\n",
    "\n",
    "Instead of hard-coding your input coordinate into your script (e.g. `longitude_dms = '123:23:34.5436W'`), get the coordinate as keyboard input from the user.\n",
    "    \n",
    "HINT: None of the code you've written should change. Just change the way you define your initial variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a longitude in DMS format: 123:23:34.5436W\n",
      "123:23:34.5436W ==> -123.39292877777778\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "longitude_dms_raw = input('Enter a longitude in DMS format: ')\n",
    "longitude_dms = longitude_dms_raw.replace(':', '')\n",
    "\n",
    "degrees = int(longitude_dms[:3])\n",
    "minutes = int(longitude_dms[3:5]) / 60\n",
    "seconds = float(longitude_dms[5:-1]) / 3600\n",
    "\n",
    "dd = degrees + minutes + seconds\n",
    "\n",
    "if 'W' in longitude_dms.upper():\n",
    "    dd *= -1\n",
    "    \n",
    "print(longitude_dms_raw, '==>', dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Follow-Up Questions:</b>\n",
    ">1. Why do programmers use keyboard input in their scripts?\n",
    ">2. What data type is returned when we get keyboard input from the user?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "#### 5.6.1.4. Practical Exercise 1.4\n",
    "\n",
    "We now have code to convert a latitude or longitude from DMS to DD. In today's lesson, we also read a local file containing some latitude and longitude information. Using the file we loaded in the lesson, use the `.find()` method to extract the DMS-formatted coordinates of the earthquake and convert to them to decimal degrees. Assume the DMS-format is limited to DDMMSS.ssN/S (latitude), and DDDMMSS.ssE/W (longitude). Determine the start and end indexes of the coordinates in the `USGS_xml_data` variable.  Use them to extract the latitude and longitude. Then, convert these coordinates to DD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\" xmlns:georss=\"http://www.georss.org/georss\"><title>USGS All Earthquakes, Past Hour</title><updated>2017-08-18T02:10:18Z</updated><author><name>U.S. Geological Survey</name><uri>https://earthquake.usgs.gov/</uri></author><id>https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_hour.atom</id><link rel=\"self\" href=\"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_hour.atom\"/><icon>https://earthquake.usgs.gov/favicon.ico</icon>\\n<entry><id>urn:earthquake-usgs-gov:us:2000a98e</id><title>M 2.5 - 81km W of Miramichi, Canada</title><updated>2017-08-18T01:47:05.040Z</updated><link rel=\"alternate\" type=\"text/html\" href=\"https://earthquake.usgs.gov/earthquakes/eventpage/us2000a98e\"/><summary type=\"html\"><![CDATA[<dl><dt>Time</dt><dd>2017-08-18 01:26:42 UTC</dd><dd>2017-08-17 21:26:42 -04:00 at epicenter</dd><dt>Location</dt><dd>46.980&deg;N 66.536&deg;W</dd><dt>Depth</dt><dd>9.00 km (5.59 mi)</dd></dl>]]></summary><georss:point>465847.64N 0663209.60W</georss:point><georss:elev>-9000</georss:elev><category label=\"Age\" term=\"Past Hour\"/><category label=\"Magnitude\" term=\"Magnitude 2\"/><category label=\"Contributor\" term=\"us\"/><category label=\"Author\" term=\"us\"/></entry>\\n</feed>'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USGS_xml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['465847.64N', '0663209.60W'] ==> 46.9799 -66.536\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "\n",
    "start = USGS_xml_data.find('<georss:point>')\n",
    "stop = USGS_xml_data.find('</georss:point>')\n",
    "\n",
    "point = USGS_xml_data[start:stop]\n",
    "\n",
    "## Multiple assignment allows us to save two variables in one line of code.\n",
    "latitude_dms, longitude_dms = point[14:].split()\n",
    "\n",
    "clean_latitude_dms = latitude_dms.upper().replace(':','').replace('N','').replace('S','')\n",
    "clean_longitude_dms = longitude_dms.upper().replace(':','').replace('W','').replace('E','')\n",
    "\n",
    "lat_dd = float(clean_latitude_dms[:2])\n",
    "lat_dd += float(clean_latitude_dms[2:4]) / 60\n",
    "lat_dd += float(clean_latitude_dms[4:]) / 3600\n",
    "\n",
    "lon_dd = float(clean_longitude_dms[:3]) \n",
    "lon_dd += float(clean_longitude_dms[3:5]) / 60\n",
    "lon_dd += float(clean_longitude_dms[5:]) / 3600\n",
    "\n",
    "if latitude_dms[-1].upper() == 'S':\n",
    "    lat_dd *= -1\n",
    "\n",
    "if longitude_dms[-1].upper() == 'W':\n",
    "    lon_dd *= -1\n",
    "\n",
    "print(point[14:].split(), '==>', str(lat_dd), str(lon_dd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Follow-Up Questions:</b>\n",
    ">1. What sub-strings did you use to extract the coordinates from the USGS data?\n",
    ">2. How did you remove the extra text from the data extracted using the `.find()` method?\n",
    ">3. How would you implement some checks in your Python script to allow for slight variations in input (e.g., lowercase `'n'`, `'s'`, `'e'`, `'w'`)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> <a id='PE2'></a>\n",
    "### 5.6.2. Practical Exercise 2: Searching for Key Words\n",
    "\n",
    "In the `data/resumes/` folder, there are several text files containing resume data.  Take a moment to go inspect them.  In this exercise, you will be reading them in and searching them for key words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.2.1. Practical Exercise 2.1\n",
    "\n",
    "Take the list of resume names provided below and read them into a dictionary. The key for each dictionary entry should be the file name without the path and extension, and the value should be the resume text. \n",
    "\n",
    "Sample output: \n",
    "```python\n",
    "{'01': 'Brielle Anastasia Ma...', \n",
    " '02': '1431 Nave\\nCharles Tow...', \n",
    " '...'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resume_filenames = ['01.txt', '02.txt', '03.txt', '04.txt', '05.txt', '06.txt', '07.txt', '08.txt', '09.txt', '10.txt']\n",
    "\n",
    "## YOUR CODE GOES HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01': 'Brielle Anastasia Mahan\\n______________________________________________________________________________\\n\\n2133 Kiowa Path\\nVirginia City, VA 23462 Cell: (214) 353-7980\\nbamahan@gmail.com  Current Top Secret/ SCI Clearance w/ CI Poly\\n______________________________________________________________________________\\n\\nPROFILE\\nHighly skilled All-Source Intelligence Analyst assigned to DIA, Defense Combating Terrorism Center. Multi-dimensional individual with 7 years military and government contract experience, whose expertise and professionalism is highly sought after. Strong and developed writing and briefing capabilities established in government and military settings. Outstanding leader and proactive team player who offers unique problem solving abilities and a positive attitude.\\n\\nALL SOURCE INTELLIGENCE ANALYST\\nAll-source / Target & Lead Development / SIGINT / Social Network Analysis/ Counter Terrorism / Threat Finance / Force Protection / HUMINT Collection Management / Route Analysis / Anti-Terrorism / Social Media Analysis / Biometrics / Counter-Threat Network/ Maritime Threat / Operational Intelligence / General Military Intelligence / Counter Piracy / Counter Proliferation/ Counter Narcotics / Call-chain Analysis \\n\\nPROFESSIONAL EXPERIENCE\\n\\n**Specific details or portfolio assignments are available upon request but omitted due to sensitivities**\\nJuly 2014-Present: Defense Combating Terrorism Center | DIA | Mid-Level Intelligence Operations Analyst | Site Lead, Buffalo Group | Reston, VA\\nAll source intelligence analyst assigned to the Iraq and Syria problem set in support of SOCOM elements. Provides assessments and a wide range of intelligence products to tactical and executive customers derived from independent research and analysis of multi-discipline intelligence information. Primarily conducts target development of facilities and personalities with a specific emphasis on global facilitation networks supporting the battlespace. Defines and develops SDR\\'s and evaluations to fill intelligence gaps. Responsible for providing subject matter expert briefings to high ranking foreign officials and senior interagency partners and experience defending key intelligence points. Extensive experience organizing, participating and conducting interagency analyst exchanges and extremely effective at cultivating new relationships. Separately manages over 30 contractor personnel for administrative and on-site requirements.\\n\\nFebruary 2014- July 2014: Counter Insurgency Targeting Program (CITP), Mid-Level Analyst | Team Lead, BKM Global Enterprises | NGIC, Charlottesville, VA: All source intelligence targeting analyst responsible for identifying, depicting, and disrupting key individuals within insurgent networks operating in Afghanistan. Conducts extensive research and analysis of raw and unevaluated information, fuses call chain analysis, biometrics analysis, GEOINT, open source, and intelligence reporting information to generate all-source products including target support packages, network environment studies, and ADHOC tactical intelligence support for CJSOTF-A elements. Defines and develops SDR\\'s and evaluations to fill intelligence gaps. Provides key intelligence assessments to tactical elements and senior leadership through formal and informal briefings, papers, charts, and other formats. Supervises, trains, and performs technical editing and quality control for six analysts.\\n\\nMarch 2013- February 2014: Africa, Europe, South America Threat Network Mid-Level Analyst, The Buffalo Group Contractor, Site Lead, DIA | DCTC, San Antonio, TX: Leveraged multiple intelligence disciplines to conduct counter-threat network analysis against transnational crime and terrorist organizations in order to identify exploitable key network nodes involved with illicit financing, drug trafficking, smuggling, IED and other terror related operations throughout Africa, Europe, and South America. Depicted organizational structures, identified network vulnerabilities, and network assessments through fused intelligence products, informal RFI responses, and briefings at strategic and operational levels. Leveraged biometric, financial, and sensitive data sets to identify human terrain, establish patterns of life, and nefarious activity to identify key TTP\\'s and foster target development of key personalities, security apparatuses, facilities, and other related facilitators. Authored tailored collection requirements, identified leads and developments, and developed a wide range of fused finished intelligence products in support of operational task forces, law enforcement, national level customers, and U.S. policy makers. \\n\\nOctober 2011- March 2014: AFPAK Threat Finance Analyst, Joint Reserve Intelligence Command - USCENTCOM, San Antonio, TX: Directly led seven joint-service military analysts in conducting counter threat finance analysis aimed at detecting, disrupting and destroying IED and facilitation networks within USCENTOM. Experience using open source, financial, and sensitive data sets to trace financial transactions, identify network nodes, and exploit vulnerabilities. Provided key intelligence assessments to senior leadership through RFI responses, ANB charts, and formal briefings. Performed technical and analytical editing to ensure all assessments and formats aligned with current intelligence writing standards.\\n\\nJuly 2010 - August 2011: All Source Intelligence EUCOM, AFRICOM, and AMERICAs Analyst, Global Maritime Watch, Office of Naval Intelligence, Washington, DC: Maintained theater wide picture of civil maritime related threats, delivered daily briefings to senior Navy Intel leadership, and provided continuous threat reporting and assessments to national and fleet level customers. Delivered more than 20 intelligence briefings to senior leadership, including the Joint Chiefs of Staff, containing enemy threat posture, indications and warnings, weapons acquisition, enemy capabilities, and counterterrorism analysis. Contributed analysis and production to over 150 briefings critical to counter proliferation, counter narcotics, counter piracy and counter terrorism efforts across the globe. Authored over 30 intelligence articles for dissemination to the IC, and pioneered the writing standards for new daily product.\\n\\nJuly 2009 - July 2010\\nHUMINT Analyst, Navy Expeditionary Intelligence Command, Virginia Beach, VA: Constructed and delivered pre-deployment current threat briefings for outgoing Maritime Interdiction Operation units and HUMINT Exploitation Teams. Briefs included human terrain, threat networks, geopolitical components, and key personalities operating in the AOR. Provided reach back analytical support to deployed units and serviced RFI\\'s. Managed training, personnel records, and supplies for over 30 military members to ensure unit operational readiness. Trained more than 25 Marine Corps, Coast Guard, and Navy personnel in tactical debriefing, detainee screening, and liaison through instruction and role-playing. \\n\\nJuly 2008 - July 2009\\nCollection Management Technician and HUMINT Analyst, Joint Task Force Guantanamo Bay, Guantanamo Bay, Cuba: Designed, assigned, and managed collection plans for over 80 detainees and 20 interrogation teams, and provided HUMINT analytical support to interrogators. Supported source validations, target development, and relayed time sensitive information to CENTCOM forces. Provided key intelligence assessments to a wide range of senior leadership intelligence requirements by leveraging open source, intelligence reporting, biometric data, detainee evidence, and other sensitive data sets. Reviewed and edited over 300 Intelligence Information Reports for release and dissemination. Delivered weekly briefings to the Director of Intelligence of Joint Task Force Guantanamo Bay. Conducted daily friendly force debriefs and completed 21 detainee evaluations later presented to senior leadership to determine mobilization status of eligible detainees. \\n\\n\\nEDUCATION\\nMaster\\'s Degree - Defense Management, 36/36 hrs complete; 3.7 GPA, degree confirmed Feb 2015\\nBachelor\\'s Degree - International Relations with Concentration in Latin American Studies, American Military University, May 2012 - 3.6 GPA\\nAssociate\\'s Degree - General, Colombia College of Missouri, May 2009\\n\\nMILITARY TRAINING OR PROFESSIONAL CERTIFICATIONS\\nJoint Intelligence Support to Irregular Warfare (2014) | Proton, IC Reach, Cultweave (2013) | Palantir (2013) | DIA Network Analysis (2013)| BI2R (2012) | Google Earth (2013) | DIA Threat Finance (2013) | Open Source Intelligence (2012) |* TAC (2011) | Expeditionary Combat Skills (2010) | MAGTF Tactical Debriefing Course (2009) | ARC GIS, Analyst Notebook, Pathfinder, M3 Training (2009) | Expeditionary Intelligence \"C\" School (2008)| Naval Intelligence Specialist \"A\" School (2008)\\n',\n",
       " '02': '1431 Nave\\nCharles Town, WV\\n(757) 967-3121\\nthe.A.X@gmail.com\\n\\nAustin Xavier\\n\\nOBJECTIVE\\tSecure a position with an organization that will allow me to utilize my education and experience while contributing to its growth and development.\\n\\nEDUCATION\\tJames Madison University, Harrisonburg, VA\\n\\t\\tBachelor of Business Administration, August 2006\\n\\t\\tMajors:  International Business, Finance, and French\\n\\t\\tCumulative GPA:  3.77\\n       \\n       \\t\\tStudy Abroad:  Paris - June-July 2005\\n\\nEXPERIENCE\\n\\nOffice Associate, Bayview Aviation, Charles Town, WV\\t\\t\\t\\t\\t         (May 2013-Present)\\n* Process sales, purchase, and repair orders, including packaging and shipping parts and completing necessary U.S. Customs filing\\n* Maintain contact with repair shops to ensure parts are repaired in timely manner\\n* Effectively communicate with and support sales team\\n\\nOperations Intelligence Analyst, U.S. Air Force Reserve, Joint Base Charleston, SC            (August 2012-Present)\\n* June 2012 graduate of U.S. Air Force Basic Operations Intelligence course, Goodfellow AFB, TX\\n* Meet information needs of executive decision-makers, staff, and support agencies through production and dissemination of accurate, timely and tailored intelligence products\\n* Produce all-source intelligence, situation estimates, order-of-battle studies, and other intelligence reports and studies\\n* Deliver current intelligence and threat briefs to senior-level wing staff and aircrew\\n* Conduct research to remain current on new technologies and techniques and provide analysis of adversary threat systems\\n* Follow derivative classification procedures to ensure finished products are properly classified based on source material classification\\n\\nStudent Accounts Coordinator, Virginia College, North Charleston, SC                            (May 2010-March 2011)\\n* Identify, contact, and collect from students whose accounts are past due\\no Reduced past due cash by more than half\\n* Counsel and advise students about their school account and financial aid funding\\n* Learn, understand, and follow government regulations to determine federal student aid eligibility\\n\\nExport Transatlantic Trade Analyst, CMA CGM (America), Norfolk, VA           (September 2008-October 2009)\\n* Coordinate, review, analyze, and price requests for rates and service details\\n* File rates and rules, draft new service contracts, and handle contract amendments while complying with Federal Maritime Commission rules and regulations\\n* Analyze customer performance through the use of various reports\\n* Designated to be the focal point for refrigerated cargo pricing and service contract maintenance\\n\\nExport Services Representative, CMA CGM (America), Norfolk, VA                    (August 2006-September 2008)\\n* Promoted to the Export VIP desk in November 2006\\n* Amend and release bills of lading and other important documents\\n* Network with various internal departments to best provide service to the customer\\n* Communicate with overseas personnel to resolve documentation and logistics issues\\n\\nCERTIFICATIONS/QUALIFICATIONS\\n* Active TS/SCI clearance\\n* Created a business plan as a junior with a group of four classmates\\n* Proficiency with classified and unclassified software including MS Office, FalconView, and Cornerstone\\n',\n",
       " '03': 'HANNAH SIMPSON\\nBROOKLYN, NEW YORK\\nMID-LEVEL ALL SOURCE ANALYST | TS/SCI W/ CI POLY\\n212.923.2587 | idontknowbart@simpson.com\\n\\nSUMMARY OF QUALIFICATIONS\\n* Over six years of experience in the U.S. Army as a Cryptologic Arabic Linguist (both Iraqi and Gulf dialect; current DLPT 2+/3)\\n* Master of Science in Political Science with courseware and thesis work on terrorism dynamics and international conflict, graduated in December 2007\\n* Multi-disciplined background in analyzing intelligence, reporting communications, target development, writing reports, and briefing intelligence leadership and expeditionary commanders\\n* Maintains substantive insights into Iraq, Syria, and Gulf State political, cultural, and security issues.\\n* Knowledgeable of IC and NSA databases including DNI tools, i2 Analyst Notebook, ArcGIS, ArcView, and DCGS-A, among other SIGINT and ELINT tools.\\n\\nEXPERIENCE\\n\\nUNITED STATES ARMY, NATIONAL SECURITY AGENCY, FT. MEADE, MD. \\tAugust 2012-Present\\nArabic Language Analyst / Staff Sergeant (E5)\\n* Provided intelligence analysis, quality control of reporting, and linguistic expertise in a multi-role position.\\n* Contributed to numerous intelligence products provided to senior customers through the provision of intelligence summaries strengthened by accurate and concise analysis.\\n* Develop and maintain institutional knowledge of target country, cultural, and regional dynamics through coordination with counterpart analytic offices and discipline specialists.\\n* Meticulously analyze intelligence collection to detect trends and anomalies, and analyze communications, global, and national security data to formulate actionable intelligence reporting.  \\n\\nUNITED STATES ARMY, 4 3 BRIGADE SPECIAL TROOPS BATTALION\\t          March 2010- June 2012\\nIntelligence Analyst/ Arabic Cryptologic Linguist \\n* In a deployed capacity from 2010-2011, directly supported Operations Iraqi Freedom and New Dawn mission objectives through providing strategic intelligence reports and briefings to leadership regarding force protection, counter-insurgency, and topics supporting commander?s initiative. \\n* Provided insight and substantive advice to intelligence commanders concerning political, tribal, cultural, and security and stability dynamics at play in Iraq, especially in Anbar Province. \\n* Assisted in target network development, discovery, and profiling through the use of SIGINT tools, techniques, and linguistic expertise. \\n* Maximized mission impact through developing effective query strategies, establishing proper reporting standards, creating and maintained several quick-reference tools, and training subordinates on integrated strategic and tactical COMINT and ELINT tools.\\n\\nEDUCATION AND RELEVANT TRAINING\\n\\nMaster of Science in Political Science with an emphasis in International Relations, graduated in December 2007; wrote thesis on state-level factors affecting terrorist group formation.\\nBachelor of Arts in Political Science, May 2005.\\nBachelor of Arts in English Literature, May 2002.\\nBachelor of Arts in Film Production, May 2002. \\nA.A. in Arabic Language Studies, June 2009.  \\n\\nCommandant?s List, Warrior Leadership Course, Ft. Indiantown Gap, PA, November 2012\\nTactical signals intelligence training course, National Training Center, Ft. Irwin, April 2009\\nCryptologic Linguist training course, Goodfellow AFB, TX, 2009\\nArabic language, Iraqi dialect training, NSA/CSS Maryland Language Center, 2013\\nArabic language, Gulf dialect training, Goodfellow AFB, TX, 2009\\nCompleted 16 National Cryptologic School courses\\n\\nLANGUAGES: Arabic (DLI-trained) \\n',\n",
       " '04': 'Cameron Oogolvie\\nJUNIOR-LEVEL ALL SOURCE ANALYST\\ncoogolvie@gmail.com\\n714 244 9709\\nTS/SCI\\n\\nSUMMARY OF QUALIFICATIONS\\n* Over five years of experience in the U.S. Air Force with three years as an all-source Operations Intelligence Specialist\\n* Bachelor of Science in Political Science with a Minor in Asian History and Certificate in International Studies, anticipated graduation May 2015\\n* Recent analytical experience on Russia-Ukraine Crimea Crisis and Russian Military doctrine\\n* Knowledgeable on Microsoft Office, Tripwire Analytic Console (TAC), iSpace, M3, Google Earth, Falconview, i2 Analyst Notebook, HOT-R, OSCAR\\n\\nEXPERIENCE\\n\\nUNITED STATES AIR FORCE, VANDENBERG AFB, CA \\t\\t\\t\\t  August 2012-Present\\nOperations Intelligence Specialist / Staff Sergeant (E5)\\n* Provided All-Source Intelligence, Situation Estimates, Order-of-Battle Studies, and other ad-hoc intelligence reports and strategic briefings to senior USAF and coalition officials\\n* Recognized for providing accurate and concise written and oral intelligence products used to protect U.S. interests with a reputation for thinking clearly in times of complex operational activity with quickly changing priorities, targets and objectives. \\n* Meticulously analyze satellite, global, and national security data to formulate actionable intelligence strategies.  Subject matter expertise led to the discovery/innovation of a new analytic technique for space, utilizing non-traditional ISR methods.\\n\\nNATIONAL SECURITY NETWORK\\t\\t\\t\\t\\t         January 2014- May 2014\\nResearch Intern \\n* Utilized in-depth military capabilities expertise to provide targeted research and analysis for policy analysts and National Security Network leadership.\\n* Investigated defense acquisitions, military strategy, and national security policy. Focused on Russia-Ukraine Crimea Crisis and Russian Military doctrine, Air-Sea Battle, Offshore Control, Iranian P5+1 Nuclear Negotiations, Counterinsurgency, and South China Sea dispute.\\n* Attended expert panel discussions, meetings, and strategy sessions on Capitol Hill to gain insight on policy makers concerns and inform analytical research to help shape USG policy decisions.\\n\\nEDUCATION AND RELEVANT TRAINING\\n\\nBachelor of Science in Political Science with a Minor in Asian History and Certificate in International Studies, Arizona State University, anticipated completion May 2015\\n\\nUSAF Joint Space Operations Center (JSpOC) Fundamentals Course, July 2014\\nUSAF Airman Leadership School, Distance Learning, December 2013\\nUSAF Operations Intelligence Apprentice Course, Goodfellow AFB, TX, August 2013\\nUSAF Operations Intelligence Fundamentals Course, Goodfellow AFB, TX, March 2013\\n\\nLANGUAGES: None\\n',\n",
       " '05': 'Cowan Dylan \\nIntelligence Analyst\\n967C South Run, Wall, MD 20602\\n(814) 592-4668\\nCowanD@yahoo.com\\n\\nProfessional Summary________________________________________________________________________\\n\\nOver nine years of intelligence experience applying reach and analysis methodologies to complex military issues. Experience working with and leading analytical focal groups, creating detailed mission analysis, and providing insight to intelligence efforts. Strong analytical and problem-solving skills gained through real world experience, including deployments to the Middle East. Excellent communications skills; prepared and presented a variety of information and analytical briefs to senior military and civilian leaders. \\n\\nHighlights__________________________________________________________________________________\\n\\n* TOP SECRET clearance with SCI access ? Single Scope Periodic Reinvestigation completed 2011\\n* CI Polygraph completed Nov 2012\\n* Extensive experience with NIPR, SIPR, and JWICS resources\\n* Experienced in analysis of organizations, procedures, and systems, problem solving, and troubleshooting\\n* Leadership experience as a noncommissioned officer, team leader, and lead analyst \\n* Fully trained and experience in strategic, operational and tactical all-source  intelligence analyst\\n* Dedicated professional, with a reliable and solid work ethic and good judgment skills\\n* Excellent interpersonal, communication skills and customer services \\n       \\t\\t\\t\\nWork History______________________________________________________________________________\\n\\nVideo Forensic Lab, National Media Exploitation Center (NMEC) \\t\\t\\t          09/2014- Present\\n* Video analyst as a contractor for the K2 Group\\n* Conducted Video Exploitation for terrorist threats and counter-transnational organized crime operations worldwide with a focus in the Middle East and Africa\\n* Produced DIA Tippers and exploitation reports to support counter terrorism operations, acted as liaison to other IC elements\\n* Briefed Senior government officials on Exploitation results\\n\\nDOMEX Branch, Defense Combating Terrorism Center (DCTC) \\t\\t\\t          11/2013- 09/2014\\n* Document and Media Exploitation (DOMEX) analyst as a contractor for the Buffalo Group\\n* Conducted DOMEX for Africa and Middle Eastern based terrorist threats\\n* Produced DIA Tippers and authored IIRs to support counter terrorism operations, acted as liaison to other IC elements\\n\\nArabian Peninsula Team, Defense Combating Terrorism Center (DCTC)\\t        \\t         03/2012 ? 11/2013\\n* Counter Terrorism Analyst on the Arabian Peninsula team as a contractor for the Buffalo Group\\n* Conducted analysis for the DIA focusing on threat analysis for all countries where AQAP operates \\n* Planned, produced, and briefed senior leaders intelligence products supporting senior US policy makers, Joint Chiefs of Staff, military and civilian leaders and deployed war fighters\\n* Essential member in developing intelligence products, in the DIA and NCTC product lines\\n\\nJ2 Rotation, Defense Combating Terrorism Center (DCTC)\\t         \\t\\t                      03/2013 ? 11/2013\\n* Performed rotation as Middle East regional desk officer for the Joint Staff J2 at the Pentagon \\n* Produced 76 slides and 6 desk notes for the Chairman of the Joint Chiefs of Staff, regularly working under strict timelines to meet mission requirements and inform the highest echelons of military leaders on current intelligence issues\\n* Briefed Senior DoD and partner nations senior leaders on DoD counterterrorism issues\\n* Recognized for excellence on four occasions with the competitive ?J22 Product of the Week Award?\\n\\nCaribbean Branch, US Southern Command (USSOUTHCOM) \\t\\t\\t         03/2010 ? 03/2012\\n* Strategic geo-political analyst in the Theater Analysis Division for USSOUTHCOM. As an all-source analyst and team lead analyst, I conduct analysis with a focus on threat analysis and military capabilities for 23 countries in the USSOUTHCOM Area of Responsibility\\n* Produced, and briefed over 200 intelligence products supporting USSOUTHCOM operations\\n* Provided support for the Haitian Humanitarian Assistance and Disaster Relief Mission Operation UNIFIED RESPONSE as a Non-Traditional ISR Analyst\\n* Collaborated with multiple agencies in the Intelligence Community\\n\\nInternational Engagements Division, US Southern Command (USSOUTHCOM) \\t         03/2009 ? 03/2010 \\n* Engagements Manager for the countries in the Central and South American regions of the USSOUHTCOM Area of Focus\\n* Planned and executed over 20 intelligence  engagements and over 10 senior level military official visits\\n* Conducted open source Intelligence Seminar in Honduras to improve the intelligence capabilities of USSOUTHCOM Partner-Nation\\n* Collaborated with multiple agencies in the Intelligence Community\\n\\nUnited States Army Central Command (USARCENT) \\t\\t\\t\\t         03/2006 - 03/2009\\n* Geo-political analyst in the Intelligence Support Branch, USARCENT. \\n* All-source analyst and team leader.  \\n* Conducted threat and military capabilities analysis for 11 countries in the CENTCOM Area of Responsibility. Subject matter expert on Kuwait, Yemen, and Saudi Arabia. \\n* Participated in multiple deployments to Kuwait and Egypt in supporting USARCENT operations\\n* Planned, produced, and briefed senior leaders over 200 intelligence products supporting USARCENT\\n* Lead analyst during 2006 Israeli/Hezbollah War. Provided analysis and mission planning support by coordinating with multiple military agencies and the American Embassy in Beirut.\\n* Essential member in developing assessments on Supply Routes supporting Operation Iraqi Freedom.\\n\\nEducation__________________________________________________________________________________\\n\\n* Masters of Arts in Intelligence Studies, American Military University- Projected March 2015\\n* Bachelors of Arts in Homeland Security and Emergency Management, Ashford University- 2013\\n* Associates of Arts in General Studies, Central Texas College- 2011\\n\\nSystems____________________________________________________________________________________ \\n\\nComputer Skills: MS Windows (3.x, 95, NTx, XP, Vista, Windows 7) and Microsoft Office Suite \\nIntelligence Programs: Falcon View, Analyst Notebook, Google Earth Enterprise, C2PC, IWS, WISE, Gemini, CPOF, DCGS-A, GCCS, M3, MCS, Haystack, Iceberg, Palantir\\n\\nTraining________________________________________________________________________________\\n\\n* Army Basic Combat Training (JUL 2005 ? SEP 2005)\\n* 35F All Source Analyst Advanced Individual Training at Ft Huachuca, AZ (SEP 2005 - FEB 2006)\\n* Analyst Notebook (JUN 07)\\n* Distributed Common Ground System - Army v3 (MAR 2008)\\n* Command Post of the Future (CPOF) (MAY 2008)\\n* Asymmetric Warfare (JUN 2008)\\n* Counterintelligence Analytical Methods (AUG 2011)\\n* Al-Qaeda 101 (July 2012)\\n\\n\\n\\n\\n\\n',\n",
       " '06': 'Isaac Mahan\\n3450 South Hampton\\nAlexandria, VA\\t\\n217-883-2458\\nismahan@yahoo.com\\n\\nSecurity Clearance\\nActive Top Secret/SCI with CI Polygraph\\nDHS Suitability\\n\\nEducation\\nMissouri State University \\t\\t\\t\\t\\t\\t \\nM.S. in Defense and Strategic Studies \\n- Graduated: May 2010 \\n- Thesis Title: Financial Measures to Counter Nuclear Proliferation\\n\\nUniversity of Missouri-Columbia\\t\\t\\t\\t\\t\\t\\nB.A. in Political Science \\n- Graduated: May 2008 \\n\\nProfessional Experience\\n\\nBattelle Memorial Institute, Department of the Air Force Intelligence Analyst (September 2014-Present)\\n\\n- Conducts open source research on civil aviation issues (Awaiting DoD SCI adjudication)\\n\\nSotera Defense Solutions, Department of Homeland Security Intelligence Analyst (December 2013-September 2014)\\n\\n- Provided analytic and production support to a 24/7/365 watch center \\n- Conducted current intelligence research and analysis across open-source and classified information platforms, focusing on indicators and warnings of threats, infrastructure protection, border security, and cybersecurity \\n- Maintained operational awareness of key resources and flows of information\\n- Used IC-derived best practices to work independently on complex problems in all phases of intelligence/law enforcement analysis\\n- Triaged information and prepare analytical assessments to provide strategic and operational support to decision-making\\n- Coordinated as needed with representatives of other government agencies and participate as required in multidisciplinary working groups \\n- Wrote reports under tight timelines and strict guidelines. Includes shift work.\\n- Utilized the following information systems: AMHS, HOTR, Sharepoint, CIA Wire and Open Source Center, Tripwire Analytic Capability, TSA Selectee/No-Fly Search, and Terrorist Identities Datamart Environment (TIDE)\\nSotera Defense Solutions and Temporary Solutions, Federal Bureau of Investigation Intelligence Analyst (January 2012-December 2013)\\n\\n- Completed database research related to counter-terrorism, cyber and weapons of mass destruction \\n- Communicated with other federal law enforcement and government agencies to develop policies and share information\\n- Searched, evaluated, and analyzed open and classified sources\\n- Supported the office?s compliance and oversight requirements and reporting\\n\\nScience Applications International Corporation (SAIC), Air Force Counter-Chemical, Biological, Radiological, and Nuclear (C-CBRN) Policy Analyst (August 2010-September 2011)\\n- Revised and updated summaries of arms control treaties and agreements involving Air Force  activities \\n- Provided analytical support to the Counter-Biological and Counter-Radiological analyst teams\\n- Reviewed Air Force, Joint, and DOD documents under coordination and provided concise responses to documents compiled from other staff inputs\\n- Submitted monthly client reports tracking contractor work and deliverables\\n- Organized and supported client meetings (classified and unclassified) at SAIC facility and at the Pentagon\\n- Provided administrative support and tracked the progress of projects on client websites\\n- Prepared briefing books for client meetings and senior leader transitions\\n- Managed the office SharePoint site\\n\\nNational Defense University?s Center for the Study of WMD, Intern (May 2009-May 2010)\\n- Updated and maintained the personnel database for the WMD Center?s Program for Emerging Leaders, an interagency personnel development event designed to introduce junior and mid-level civilian and military officials to current WMD national security challenges\\n- Provided administrative support to staff members and to a number of office events\\n- Conducted open-source research to support staff member projects\\n- Created briefing books for senior staff member?s overseas trip\\n\\nOffice of U.S. Congressman Mike Pence, Intern (September 2008-December 2008)\\n- Provided research support to staff members on legislative issues \\n- Drafted email and mail correspondence to constituents and maintained the office?s constituent email database\\n- Answered phone calls and supported other constituent service programs \\n- Helped maintain office upkeep and supplies\\n\\n References\\n-Ms. Tami Stukey- Program Manager, SAIC Phone: 703-415-3342 Email: tami.l.stukey@saic.com \\n-Mr. Forrest Waller- Senior Research Fellow, National Defense University Phone: 202-685-4235 \\nEmail: WallerF@ndu.edu\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " '07': '\\nAubrey Tinger\\nA.Tinger@gmail.com\\n404-900-4520 (cell)\\n\\nCLEARANCE\\nTS/SCI\\n\\nEDUCATION\\n\\n* BA, Anthropology, minor in Sociology, Georgia State University, 2007\\n* Associate?s Degree, Middle Eastern Studies and Arabic, Defense Language Institute Foreign Language Center, Monterey, CA, 2004\\n\\nCERTIFICATIONS\\nModern Standard Arabic Refresher course, Diplomatic Language Services, no final test administered, Spring 2012 \\nModern Standard Arabic, Defense Language Proficiency Test Score 2/2+, 2007\\n\\nQUALIFICATION HIGHLIGHTS\\n* Extensive knowledge of social science research methodologies, foreign language, and culture producing high-level analytical material supporting the United States government in current and future operational environments\\n* Strong background in the Arabic language and Middle Eastern regional studies\\n* Strong background in Aghan and Pakistani culture and regional studies\\n\\nTECHNICAL SKILLS & EXPERTISE\\n* Conversational Spanish and Arabic, with strong translation skills\\n* SPSS, Microsoft Office, CIDNE, TIGRNET, HOTR, Google Earth, TAC, Palantir\\n\\nPROFESSIONAL EXPERIENCE\\nL-3 Data Tactics Corporation, DARPA Nexus 7\\t\\t\\t\\t01/2011 ? 01/2014\\nIntelligence Analyst/Request for Support Manager\\n* Facilitated the fulfillment of requests from forward deployed customers; over 40 to date\\n* Supplied credible intelligence reports to support customer requests ?to include security and stability, threat assessments, counter-insurgency options development, and insurgent and militant organization and theory\\n* Deployed to Afghanistan for 60 days from July ? September 2011 and May- July 2013\\n* Supervised requests directly while forward deployed; approximately 20 to date\\n* Provided customers with direct interface to ensure a quality product and relays customer requests to CONUS team in a timely manner\\n* Managed multiple requests that were developed for the Commander?s Initiative Group and  COMISAF directly\\n* Fulfilled numerous multi-agency intelligence requests for the Afghanistan Threat Finance Cell and facilitated tool development for forward deployed analysts\\n* Worked in multi-agency environment and supplied information to support reports generated by DIA, DEA, FBI, and SIGAR\\n\\nL-3 Data Tactics Corporation, Localview                                                                    12/2012 ? 01/2014\\n* Volunteered over 40 hours of personal time to assist in the primary development of Localview\\n* Conducted literary review, data set research and cataloguing, and open source intelligence research for tool demonstration purposes\\n\\nHuman Terrain System, Reachback Research Center\\t\\t\\t\\t09/2009 ? 12/2010\\nCultural Analyst\\n* Provided analytical experience to regionally focused research teams supporting requirements generated from primary customers deployed to combat theaters of operation \\n* Employed working knowledge of tribal system and make-up, current politics and policies, religious history and sectarianism, minority ethnic groups residing in Iraq, ancient history that influences modern-day issues \\n* Researched and wrote short and long-term reports on various religious, cultural, and political key movements and individuals in foreign areas of interest\\n* Generated reports based upon non-traditional sources, multiple-domains, networking across the intelligence community and deployed assets, as well as leveraging of expertise throughout the command structure of U.S. Army Human Terrain System\\n* Utilized analytical methods to assess and report on foreign political, social, and cultural systems with which government operators may interact \\nResearch Topics\\n* Politically Motivated Terrorism: Research Methodologies, Motives, and Preventative Measures\\n* The Effects of the Iraqi Diaspora\\n* Iraqi National Literacy Campaigns & Adult Education Programs\\n* National and Public Support for Females in the Iraqi Security Forces\\n* Women?s Initiatives and Progressive Campaigns in Iraq\\n* Compiled information for over eleven Iraqi Provincial Profiles to include tribal data\\n* Compiled information for over fifteen Afghan Provincial Profiles to include tribal data\\n* The History of the Sinaloa and Juarez Drug Cartels in Mexico, report for program director for State Department use\\n\\nU. S. Army, Operations NCO\\t\\t\\t\\t\\t\\t\\t01/2008 ? 12/2008\\n* Staff Sergeant in Psychological Operations \\n* Operations NCO operating at detachment level \\n* Conducted mission coordination between Brigade level S2 and S7 and the Tactical PSYOP teams\\n* Participated in frequent meetings with local nationals gathering PSYOP assessments assisting BDE mission planning, interacting sympathetically and engagingly while maintaining analytical perspective\\n* Responsible for gaining atmospherics with specific Target Audiences\\n* Developed matrices and reporting systems for collected data\\n* Wrote detailed reports regarding interaction with Local Nationals and assessed current situations after every mission\\n* Briefed BDE staff on PSYOP plans that directly supported BDE and DIV Commander?s intent while attending weekly Counter-IED and Security Working Group meetings \\n\\nForeign Service\\nData Tactics Corp., Kabul, Afghanistan\\t\\t\\t\\t\\tSummer 2013\\nData Tactics Corp., Kabul, Afghanistan\\t\\t\\t\\t\\tSummer 2011\\nU. S. Army, Baghdad, Iraq\\t\\t\\t\\t\\t\\t\\t01/2008 ? 11/2008\\n\\nCarhuaz, Peru, Study Abroad Program\\t\\t\\t\\t\\tSummer 2007\\n* Studied medical and environmental anthropology\\n* Conducted intensive, self-directed, ethnographic study of Quechuan life and use of indigenous Andean plant life\\n* Developed strong anthropological research and analysis skills\\n\\n\\n',\n",
       " '08': 'Brayden Solice\\nContact Information ? 3243 Forest Tree Bluff, McLean VA 22101/ 910.887.6194/bsolice@gmail.com\\nClearance: TS/SCI CI Poly \\nProposed Employment Status: Full-time\\nAvailability Date: As Needed  \\nEducation:\\nMA, Intelligence Studies, American Military University\\nGraduate Certificate, Asymmetric Warfare, American Military University \\nBA, Political Science, Charleston-Southern University\\nManagement / Technical Skills\\nSummary of Relevant Experience\\n* Current position as a TIDE Analyst provides both tactical and strategic perspective on the GWOT, including existing (al Qaeda) and emerging threats (Boko Haram)\\n* Extensive experience creating briefs, reports, and presentations for both written and oral delivery to subordinates, peers, and seniors\\n* Service in the Marine Corps, including deployment to Iraq in support of OIF, provides situational awareness of the GWOT, especially as it relates to the Middle East\\n* Performed field intelligence collection, reporting, and writing on potential threats in both al-Anbar Province and the Philippines/SE Asia\\n* Graduate-level education focused on law enforcement, terrorism, insurgency, and asymmetric warfare, including courses such as Counterterrorism, Threat Analysis, Insurgency & Revolution, Criminal Intelligence Analysis, Human Intelligence, and Strategic Intelligence\\n* Training and experience with a number of intelligence tools and database search applications, including Guardian, IDW, and QTIP\\n* Current TS/SCI CI Poly Security Clearance\\nOther Beneficial Experience Desirable to the Customer\\n* FBI Investigate Data Warehouse tools including Batch Query, Chiliad, and Analytical Searches\\n* Guardian\\n* FANTOM Data Visualization\\n* Query Tracking and Initiation Program (QTIP)\\n* Lexis-Nexis Accurint for Law Enforcement\\n* TIDE\\n* CCD/ACRQS\\nProfessional Experience Synopsis\\nNovember 2012 ? Present: TIDE Analyst, National Counterterrorism Center/ Strategic Intelligence Group, McLean, VA\\n* Responsible for analysis of multiple intelligence sources in order to process nominations to the Watchlist maintained by the Terrorist Screening Center (TSC)\\nJanuary 2012 ? November 2012: National Security and Policy and Advisor, FBI Foreign Terrorist Tracking Task Force (FTTTF)/ Sotera Defense Solutions, Inc., Crystal City, VA\\n* Responsible for a variety of assignments to include responses to Congressional and White House inquiries, budget and policy writing, developing and measuring of metrics\\n* Responsible for creating PowerPoint presentations, written presentations, and  providing scheduled and impromptu briefings on intelligence topics, FBI operations and other areas as assigned\\n* Trained in the use of a number of intelligence databases, datasets and search tools\\n\\nJuly 2011 ? January 2012: Corporate Recruiter/ DoD Intelligence Contracts Proposal Lead, Sotera Defense Solutions, Inc. (Corporate), McLean, VA\\n* Responsible for full life-cycle recruiting of qualified candidates for a wide range of Intelligence Community contracts supporting CONUS and OCONUS customers\\n* Responsible for maintaining awareness of current and emerging threats to the U.S. and U.S. interests abroad and briefing peers and senior personnel\\n* Responsible for coordinating with DoD Contract Program Managers on new and existing contracts and proposals\\n* Responsible for regularly scheduled and impromptu briefings to peers and senior company personnel as assigned\\n\\nMay 2011 ? July 2011: Intelligence Analysis Intern, Sotera Defense Solutions, Inc. (Corporate), McLean, VA\\n* Responsible for leading a team of four other interns throughout the internship period, including creation of tactical and strategic-level intelligence products\\n* Responsible for daily research using open source materials in order to produce a summary of current events and threats to the U.S. and its interests\\n* Responsible for regular briefings to peers, senior company personnel, and members of various intelligence agencies\\n\\nMay 2006-May 2010: Non-Commissioned Officer, United States Marine Corps\\n* Duty stations included Okinawa, Japan and Jacksonville, NC, as well as deployments to Kuwait and Iraq in support of OIF, and the Philippines in support of the GWOT\\n* Responsible for a variety of tasks and duties including leadership and mentoring of junior Marines, to include formal and informal training and classroom sessions on counterinsurgency and counterterrorism topics and material. Responsible for similar training given to peers and senior Marines during pre-deployment training and while in-country\\n* Responsible for field collection of tactical intelligence while deployed and briefing of information collected to peers and senior Marines\\n* Responsible for development of threat profile for Philippines/SE Asia prior to and during deployment with 31st MEU and briefing to peers and senior Marines\\n\\n\\n\\n\\n\\n',\n",
       " '09': 'Rachel Bijoux\\n(571) 359-7764\\nJewel@aol.com\\nChantilly, VA\\n\\nActive DoD TS/SCI with CI Poly\\n\\nAll-source intelligence professional with seven years of experience: Counter-IED Operations and Intelligence Integration Center (COIC) and U.S. Special Operations Command (SOCOM) targeting, research, analysis, and management at the tactical, operational, and strategic levels in both civilian and military realms\\n\\nSeeking a challenging position to utilize training and expertise in order to make a genuine contribution to the US Intelligence Community while increasing knowledge and aptitude\\n\\nRelevant Experience:\\n\\nALL-SOURCE INTELLIGENCE ANALYST / SME\\nCounter-IED Operations and Intelligence Integration Center (COIC), Reston, VA / Afghanistan Oct 12 - Apr 14\\n\\n* Participated in production, indications and warning, collection management, targeting, imagery, network analysis, counterintelligence, counter-terrorism, information operations, foreign disclosure, international engagements and threat analysis\\n* Initiated and conducted research efforts, plans, coordinates, and synthesizes research to produce all-source intelligence products and responses to the customer, which is integral in the planning and conducting of military operations\\n* Graduate of the Attack the Network Advanced Analytical Program (A3P); proficient with tools used to analyze, portray, and target enemy threat networks focusing on countering Improvised Explosive Devices (IEDs). Tools include: Palantir, Analyst Notebook, Google Earth, ArcGIS, TIGR and CIDNE, Querytree, M3, DCGS-A, WebTAS, and other toolsets specific to the COIC and JIEDDO\\n\\nTEAM J2, JOINT SPECIAL OPERATIONS TASK FORCE (U.S. Army- First Lieutenant) May 11 - Nov 11\\nUnited States Special Operations Command (USSOCOM) Afghanistan\\n\\n* Nominated and processed 195 targeting recommendations and numerous all-source products to JSOTF Regional J2 and Commander, resulting in over 110 operations and 188 detained individuals\\n* Collaborated with Intelligence Surveillance Reconnaissance (ISR) Collection Manager to prioritize daily targeting efforts leading to the lethal targeting of high-value individuals (HVIs)\\n* Liaised to conventional force S2s and fusion cells to maximize targeting efforts within the area of operation\\n* Briefed enemy situation template (SITTEMP) and intelligence concept of operations (CONOP) for each mission to the Strike Force, Task Force Commander, Task Force Regional J2 and other S2 entities daily\\n* Managed three all-source analysts, three SIGINT analysts, and three members of a HUMINT cell\\n\\nJSOTF TARGETING ANALYST (U.S. Army - First Lieutenant)Dec 10 - May 11\\nUnited States Special Operations Command (USSOCOM) Afghanistan\\n\\n* Nominated, developed, and created high value targets for lethal U.S. Military targeting and products to support team efforts to include: enemy SITEMPs, CONOPs, Intelligence Summaries (INTSUMS), and link diagrams\\n* Responsible for all phases of operational and tactical planning in support of U.S. special operations, including targeting of high value individuals\\n* Collaborated with SIGINT, HUMINT, GEOINT entities, battle-space owner, and elements at various echelons throughout the IC to fuse all intelligence disciplines to find, fix, and finish targets using F3EA model\\n* Conducted tactical, operational, and strategic intelligence research and analysis and briefed the Commander, the J-2, and the team. Provided direct support to combat maneuver and tactical operations\\n* Generated tactical questioning plans and source directed requirements (SDRs) to drive the exploitation process at detention facilities and ground force teams using HUMINT and SIGINT reporting\\n* Utilized analytical tools such as Intelink, Analyst Notebook, S3, SKOPE Tools, TIGR, Google Earth, and CIDNE\\n\\nMULTI-FUNCTION TEAM OFFICER IN CHARGE (U.S. Army Reserve - Second Lieutenant) May 09 - Sep 10\\nA Co, 325th MI BN (BfSB), Ft. Devens, MA\\n\\n* Provided leadership combat service and support to eleven-man collection team consisting of two Signals Intelligence Analysts, (35N), one Counter Intelligence Agent (35L), and eight Human Intelligence Collectors (35M)\\n* Ensured all team members are trained and combat ready for ongoing intelligence support and deployment in support of GWOT to include cross-leveled, non-organic Soldiers\\n* Provided realistic training to increase battlefield survivability and mission success; observed training in order to provide critical and constructive feedback to the teams increasing overall team development and communication\\n\\nHUMINT / CI ANALYST (U.S. Army HUMINT Collector, 35M, Staff Sergeant) May 08 - May 09\\nCENTCOM J2X, Ft. Devens, MA\\n\\n* Carried out thorough research, analysis, and assessment of OIF detainees who posed enduring threat to the security of US and Iraq, in order to support theater operations, Multi-National Forces-Iraq and US Central Command\\n* Developed and shared knowledge of theater of operations and Tactics Techniques and Procedures, contributing to teams collective knowledge base\\n* Leveraged an array of intelligence analysis tools, national level databases and message retrieval systems to include: Analyst Notebook, DCGS-A, CIDNE, M3, Pathfinder, Harmony, BATS, and DSOMS\\n\\nHUMINT COLLECTION SERGEANT (U.S. Army Reserve HUMINT Collector, 35M, Staff Sergeant) Aug 07 - May 09\\nA Co., 325 MI BN, Devens, MA\\n\\n* Conducted tactical HUMINT collection; debriefings, interrogations and elicitations in English and foreign languages with use of an interpreter for intelligence and force protection operations\\n* Prepared and edited Tactical Interrogation Reports, Intelligence Information Reports\\n* Utilized CI/HUMINT Reporting in order to provide analysis and conduct briefings to commanders\\n* Also served in multiple capacities in tandem; Platoon Sergeant, Company level Equal Opportunity Representative and Duty Appointed Retention Non-Commissioned Office\\n\\nEducation:\\n\\nGraduate Studies in Education: Middle School Math, Cambridge College, Cambridge, MA (2004)\\n\\nB.S. Hotel Restaurant, & Travel Administration, University of Massachusetts, Amherst, MA (1993)\\n\\nRelevant Training:\\n\\nSOCOM Staff Integration Seminar (SIS) Course, Ft. Bragg, NC (2011)\\nWeapons Intelligence Course (WIC), Ft. Huachuca, AZ (2010)\\nMilitary Intelligence Basic Officer Leadership Course (BOLC) III, for 35D, Ft. Huachuca, AZ (2010)\\nBasic Officer Leadership Course (BOLC) II, Ft. Sill, OK (2009)\\nCounter Intelligence Analytical Methods Course, Ft. Devens, MA (2009)\\nJoint Special Operations Intelligence Course, Ft. Devens, MA (2009)\\nJTF Analysis Fundamentals and Tools Course, Ft. Devens, MA (2008)\\nPalantera, National Geospatial Agency (NGA), Ft. Devens, MA (2008)\\nTotal Army Instructor Training Course (TAITC), Ft. Devens, MA (2008)\\nBasic Noncommissioned Officer Course, Common Core & 35M Phase 2, Ft. Dix, NJ & Ft. McCoy, WI (2007,2008)\\nHuman Intelligence Collector Course (35M), Ft, Devens, MA (2007)\\n\\nAwards and Decorations:\\n\\nJoint Service Commendation Medal, Army Commendation Medal, Joint Service Achievement Medal, Army Achievement Medal, Army Good Conduct Medal, Army Reserve Components Achievement Medal (2), National Defense Service Medal, Afghanistan Campaign Medal (Two Campaign Stars), Global War on Terrorism Service Medal, Noncommissioned Officer Professional Development Ribbon (2), Army Service Ribbon, Overseas Service Ribbon, Armed Forces Reserve Medal w/ M Device, Career Counselor Badge\\n\\nUS Army Reserve Responsibilities\\n\\nCurrently serves as an S3 Liaison Officer in the rank of CPT for US Army Reserve, 203rd Military Intelligence Battalion, Aberdeen Proving Ground, MD in support of Technical Intelligence (TECHINT) requirements and training.\\n\\nReferences available upon request\\n\\n\\nResume from ClearanceJobs.com \\n',\n",
       " '10': \"SKYLAR MATTHEWS\\nmathewss@yahoo.com\\n(912)-537-5391\\n\\nWork Experience\\n\\nQualifications Summary\\nMs. Mathews has eleven years of intelligence analysis experience. Prior to her employment\\nwith CACI, Ms. Mathews worked at Pluribus International and served with the U.S. Army.\\nShe assisted military and Department of Defense (DoD) clients in the production of\\nintelligence products to support tactical military operations and DoD counterintelligence\\nagainst foreign intelligence and security service operations. \\n\\nCACI (April 2008 ?Nov 2014)\\nHours worked 40+ weekly\\nIntelligence Analyst 2\\nEmployed as an intelligence analyst supporting a government customer located on Kirtland\\nAFB, NM. Duties include analyzing all-source intelligence and exploitation of various IC\\ndatabases to support customer requirements. I served as the primary lead on commercial market research, and open-source intelligence analysis, and intelligence fusion.\\nOther duties include conducting open-source exploitation and analysis, identifying trends and patterns in target areas and identify vulnerabilities, methodologies, and capabilities of hostile states and independent actors. I was responsible for the development of briefings and delivery of briefings to the client. I have an expert track record of providing detailed and accurate analysis for both immediate and long term tasking. I had extensive client interface to further develop client solutions and mission needs. I also served in an Ad-hoc computer support as needed to both team members and the clients.\\n\\nPluribus International (December 2006 ? April 2008)\\nHours worked 40+ weekly\\nCounterintelligence/Intelligence Analyst\\nCounterintelligence/intelligence analysis at the Counterintelligence Field Activity (CIFA).\\nDuties include evaluating intelligence to create target packages, operation support plans,\\nwhite papers, and intelligence reports, while supporting combatant commanders and active\\nintelligence operations. Designed, developed and implemented a counterintelligence/intelligence community wide project pertaining to a foreign country?s intelligence and security services operations. I received multiple compliments from the Joint Warfare Analytical Center, the Defense Intelligence Agency, and the Director of National Intelligence for my work.\\n\\nUnited States Army (September 2002 ? September 2006)\\n\\nJanuary 2006 - September 2006\\nHours worked 40+ weekly\\nIntelligence NCO, US Army, Fort Stewart , Georgia\\nSenior Intelligence Non-Commissioned Officer (NCO) for a Cavalry Squadron. In charge of\\ndaily intelligence requirements for the commander to Include IPB preparation, intelligence\\nestimates, intelligence briefs, SSO duties for the Squadron, personnel security, information security, and physical security requirements. Instructed junior intelligence analysts on job functions and performance, including understanding of ASAS-L, CPOF, Falcon View, Worldview, Intelink, SIPRnet, NIPRnet and other applications.\\n\\nJanuary 2005 - January 2006\\nHours worked 40+ weekly\\nIntelligence NCO, Balad, Iraq, Forward Operating Base Paliwoda\\nIntelligence NCO for a Cavalry Battalion forward deployed in support of Operation Iraqi\\nFreedom III. I was in charge of all aspects of Intelligence operations for the battalion; to include Force Protection by using redcell and terrorist capabilities to identify security gaps and vulnerabilities. I conducted security tests to ensure effective force protection standards.\\nHUMINT Targeting by developing and maintaining databases of suspected terrorist and\\nknown terrorists. I developed in depth targeting folders on terrorist with-in AOR/AOI.\\nIdentifying and eliminating intelligence gaps. I used multiple sources to include Humint\\nteams, informants, detainees, debriefings, SIPR/NIPR/Open-source to identify potential\\nthreats with in AOR/AOI, Developing and maintaining SIPR website for the Intelligence\\nsection using ASAS-L/CS2. Preparing Intelligence briefings and conducting briefings using\\nthe ASAS-L, SIPR/NIPR/Open-source, crimelink, analyst notebook and developed databases.\\nBattle Tracking using ASAS-L, Falconview, Worldview, and SIPR/NIPR nets. Assisting in\\nthe Detention of captured terrorists, processing of the detainees to included DOCEX,\\nWEAPONEX, Currency tracking, and ensuring the welfare of the detainees. TTP\\ndevelopment tracking for IED, VBIED, SVBIED, SIED and EFP's within AOR/AOI. Raven\\ntactical un-manned aerial vehicle pilot and flight/Mission NCOIC with over 500 flight hours including its usage for target development, recon, terrain denial and counter fire missions.\\n\\nMay 2004 - December 2004\\nHours worked 40+ weekly\\nBattalion Intelligence Specialist, Fort Stewart, Georgia\\nBattalion Intelligence Specialist for a Cavalry Battalion, which involved the daily aspects of personnel security, which involved processing and maintaining security clearances for qualified soldiers, developing briefings for information security procedures and guidelines. I was in charge of inspecting deficiencies in security protocols and procedures. I provided counseling and guidance to subordinates, and developing expert proficiency with ASAS-L, SIPR/NIPR nets. I served as MAP custodian for Battalion. I prepared the intelligence requirements for the Battalion for deployment to Iraq : To include IPB of AOR/AOI using multiple sources to pre-identify threats and possible threats in AOR/AOI and surrounding areas. Identified and eliminated intelligence gaps for deployment. I was responsible for fielding ASAS-L to the battalion.\\n\\nApril 2003 - May 2004\\nHours worked 40+ weekly\\n3rd BCD Intelligence Analyst, OSAN AB , South Korea\\nIntelligence Analyst and ITO Manager in a joint theater command environment, which\\ninvolved maintaining personnel security and information security files on 48 high ranking\\npersonnel within the BCD. Personnel security representative for 3rd BCD. I was in charge of The ITO (Interim Targeting Operation) for North Korea within the 3rd BCD, and Rain-Drop\\nDPMTS (1of 4 Army) Operators certified by US AIRFORCE. I produced over 1,000\\ntargeting folders on North Korean C4I structures and personnel using Rain-Drop DPMTS,\\nJWICS/SIPR/NIPR/Open source, ASAS RWS, ASAS Standalone, SCI/TK systems, and\\nNGA imagery. I performed battle tracking using RWS, C2PC, GCCK, GCCK-s during both\\nreal world events and training events such as UFL, IronEagle and other Air force and Army\\ntraining cycles.\\n\\nEducation\\nCurrently pursuing a Bachelor of Science in Information Technologies (Expected graduation September 2017)\\nAmerican InterContinental University\\n21 Credit hours towards an Associate Degree in Intelligence Operations\\nCochise College (AZ) 2003\\n\\nMilitary Intelligence School, Fort Huachuca, AZ 2002-2003\\n\\nCACI Virtual University courses\\nCompliance 2014: Ethical Decision-Making 2014\\nCompliance 2014: Integrity Leadership 2014\\nCompliance 2014: Code of Ethics 2014\\nCompliance 2014: CACI-specific Policies, Procedures and Busi... 2014\\nContract Labor Category Verification 2014\\nHiring & Using Ex-Government Employees (Government Contractors) 2013\\nCompliance 2013 - Internet & Email Usage 2013\\nCompliance 2013 - Code of Ethics 2013\\nCompliance 2013 - CACI Compliance (Current Employees) 2013\\nIntroduction to the CACI Delivery+ Framework 2013\\nCIS - Continuity and Availability Management 2013\\nCACI Learning Series: Project Management Professional (PMP) ... 2013\\nCACI Learning Series: CACI Clearance Program 2013\\nCACI Learning Series: Business Development 2013\\nCACI Learning Series: Situational Leadership 2013\\nNK Denial and Deception, CIFA 2007\\nAFRICOM Implications for African Security and U.S.-African Relations, AEI, 2007\\nHumit/CI Organizations, JIVU 2007\\nAnalytical Tradecraft Course, JIVU, 2005\\nNational Intelligence Course, JIVU, 2005\\nForeign Denial and Deception Course, JIVU, 2005\\nCounter Terrorism Analyst Course, JIVU, 2005\\nAsymmetric Threat Course, JIVU, 2005\\nSurveillance Detection Course, JIVU, 2005\\nRaven Pilot Course and License, Redstone, 2004\\nASAS-L Refresher Course, FT Stewart, 2004\\nGCCK/-S C2PC beginner and Advanced Course, Youngson, 2003\\nASAS-L Training/Fielding Course, Youngson, 2003\\nRain Drop Digital Point Targeting Mensuration System Course , US Air Force, 2003-2004\\n\\nClearances\\nTS-SCI and DOE Q\\n\\nIntelligence System/Software Experience: C2PC,GCCK, GCCK-S, Falcon-view, World-\\nView, ASAS-L, RWS block 1 and 2, CPOF, SIPR/NIPR nets, RDDPTMS, JWICS, Analyst\\nNotebook, ADIMS, M3, Intellipedia, WebTAS 2.0, WebTAS 3.1, TTIC/NCTC, ICI, WISEISM,\\nPortico, Gemini and Interpol?s I24/7, Source, Talons, CS2, BFT, FBCP, ALIEN,\\nArtemis (SMLA), Athena, GCCS-13, FISHNet, i2D, WIZARD, A-Space/J-Space, Google\\nEarth, RDOG, HOTTR, Anchory, SNAG, all Microsoft products, and many others.\\n\\nProfessional References:\\nCaleb Quinta, Director 505-470-7124\\nJace Charles-Doogan, SIA 505-470-8976\\nSara Ravenwood COL (Ret), Director 505-554-1754\\n\"}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "path = 'data/resumes/'\n",
    "\n",
    "resume_dict = {}\n",
    "\n",
    "for resume in resume_filenames:\n",
    "    \n",
    "    with open(path + resume) as my_file:\n",
    "        resume_text = my_file.read()\n",
    "        resume_dict[resume[:2]] = resume_text\n",
    "        \n",
    "resume_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.2.2. Practical Exercise 2.2\n",
    "\n",
    "Using `input()`, ask the user for a keyword to search for. Then, iterating over the dictionary you just created, search for and print out the filenames of all the resumes containing the input keyword. \n",
    "\n",
    "Example:\n",
    "\n",
    "| Example Input | Expected Output |\n",
    "|:----:|:---:|\n",
    "| `TS/SCI` | `02, 03, 04, 07, 08, 09` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a resume keyword: TS/SCI\n",
      "09\n",
      "03\n",
      "04\n",
      "08\n",
      "02\n",
      "07\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "keyword = input('Enter a resume keyword: ')\n",
    "\n",
    "for filename, resume_text in resume_dict.items():\n",
    "    \n",
    "    if keyword.lower() in resume_text.lower():\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.2.3. Practical Exercise 2.3 \n",
    "\n",
    "Edit the code from the last section to take multiple keywords from the user, separated by commas.  Print out resume names that contain all the keywords. \n",
    "\n",
    "HINT: Strip all whitespace from the beginning and end of each keyword.\n",
    "    \n",
    "| Example Input | Expected Output |\n",
    "|:----:|:---:|\n",
    "| `TS/SCI, Intelligence, Analyst, All Source` | `03, 04` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter resume keywords: TS/SCI, Intelligence, Analyst, All Source\n",
      "03\n",
      "04\n"
     ]
    }
   ],
   "source": [
    "## INSTRUCTION SOLUTION(S) ##\n",
    "keywords = input('Enter resume keywords: ').split(',')\n",
    "\n",
    "for filename, resume_text in resume_dict.items():            \n",
    "    \n",
    "    foundall = True\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        \n",
    "        if not keyword.strip().lower() in resume_text.lower():\n",
    "            foundall = False\n",
    "            break\n",
    "            \n",
    "    if foundall:\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Administrative'></a>\n",
    "<hr>\n",
    "## 5.7. Administrative Notes\n",
    "* Save your Lesson 5 .ipynb file to your H drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b><center>UNCLASSIFIED</center> </b>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
